{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Based Models for a Regression Problem, and Hyperparameter Tuning\n",
    "\n",
    "We will work on Review dataset to see how Tree-based regressors (Decision Tree, Random Forest), along with efficient optimization techniques (GridSearch, RandomizedSearch), perform to predict the log_votes field of our review dataset.\n",
    "\n",
    "    Reading the dataset\n",
    "    Exploratory data analysis and missing value imputation\n",
    "    Stop word removal and stemming\n",
    "    Scaling numerical fields\n",
    "    Splitting the training dataset into training and validation\n",
    "    Computing Bag of Words features\n",
    "    Fitting tree-based regressors and checking the validation performance\n",
    "    \n",
    "Overall dataset schema:\n",
    "\n",
    "    reviewText: Text of the review\n",
    "    summary: Summary of the review\n",
    "    verified: Whether the purchase was verified (True or False)\n",
    "    time: UNIX timestamp for the review\n",
    "    rating: Rating of the review\n",
    "    log_votes: Logarithm-adjusted votes log(1+votes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading the dataset\n",
    "\n",
    "We will use the pandas library to read our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/aws-samples/aws-machine-learning-embark-nlp/raw/master/DATA/NLP/EMBK-NLP-REVIEW-DATA-CSV.csv'\n",
    "#df = pd.read_csv(url,index_col=0,parse_dates=[0])\n",
    "df = pd.read_csv(url,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>log_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Stuck with this at work, slow and we still got...</td>\n",
       "      <td>Use SEP or Mcafee</td>\n",
       "      <td>False</td>\n",
       "      <td>1464739200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I use parallels every day with both my persona...</td>\n",
       "      <td>Use it daily</td>\n",
       "      <td>False</td>\n",
       "      <td>1332892800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Barbara Robbins\\n\\nI've used TurboTax to do ou...</td>\n",
       "      <td>Helpful Product</td>\n",
       "      <td>True</td>\n",
       "      <td>1398816000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have been using this software security for y...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>1430784000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If you want your computer hijacked and slowed ...</td>\n",
       "      <td>... hijacked and slowed to a crawl Windows 10 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1508025600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>I've never used a Rosetta product before, but ...</td>\n",
       "      <td>Excellent Product</td>\n",
       "      <td>True</td>\n",
       "      <td>1350000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Acronis comes through for me when Windows back...</td>\n",
       "      <td>Acronis Just Great!</td>\n",
       "      <td>True</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>on the life-cycle of this item &amp; the other vis...</td>\n",
       "      <td>still over 3 yrs. left..</td>\n",
       "      <td>True</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Piece of S---.  Just wanted a staic non-video ...</td>\n",
       "      <td>sucks</td>\n",
       "      <td>True</td>\n",
       "      <td>1427068800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>So far it has been very nice and easy to use.</td>\n",
       "      <td>Love AVG</td>\n",
       "      <td>True</td>\n",
       "      <td>1420156800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Stuck with this at work, slow and we still got...   \n",
       "1  I use parallels every day with both my persona...   \n",
       "2  Barbara Robbins\\n\\nI've used TurboTax to do ou...   \n",
       "3  I have been using this software security for y...   \n",
       "4  If you want your computer hijacked and slowed ...   \n",
       "5  I've never used a Rosetta product before, but ...   \n",
       "6  Acronis comes through for me when Windows back...   \n",
       "7  on the life-cycle of this item & the other vis...   \n",
       "8  Piece of S---.  Just wanted a staic non-video ...   \n",
       "9      So far it has been very nice and easy to use.   \n",
       "\n",
       "                                             summary  verified        time  \\\n",
       "0                                  Use SEP or Mcafee     False  1464739200   \n",
       "1                                       Use it daily     False  1332892800   \n",
       "2                                    Helpful Product      True  1398816000   \n",
       "3                                         Five Stars      True  1430784000   \n",
       "4  ... hijacked and slowed to a crawl Windows 10 ...     False  1508025600   \n",
       "5                                  Excellent Product      True  1350000000   \n",
       "6                                Acronis Just Great!      True  1394841600   \n",
       "7                           still over 3 yrs. left..      True  1394841600   \n",
       "8                                              sucks      True  1427068800   \n",
       "9                                           Love AVG      True  1420156800   \n",
       "\n",
       "   rating  log_votes  \n",
       "0     1.0   0.000000  \n",
       "1     5.0   0.000000  \n",
       "2     4.0   0.000000  \n",
       "3     5.0   0.000000  \n",
       "4     1.0   0.000000  \n",
       "5     5.0   1.791759  \n",
       "6     5.0   0.000000  \n",
       "7     5.0   0.000000  \n",
       "8     1.0   0.000000  \n",
       "9     4.0   0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>log_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.500000e+04</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>55000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.369527e+09</td>\n",
       "      <td>3.568018</td>\n",
       "      <td>0.529112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.150230e+08</td>\n",
       "      <td>1.626900</td>\n",
       "      <td>0.960084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>9.427104e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.322676e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.405382e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.448064e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.537142e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.799753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time        rating     log_votes\n",
       "count  5.500000e+04  55000.000000  55000.000000\n",
       "mean   1.369527e+09      3.568018      0.529112\n",
       "std    1.150230e+08      1.626900      0.960084\n",
       "min    9.427104e+08      1.000000      0.000000\n",
       "25%    1.322676e+09      2.000000      0.000000\n",
       "50%    1.405382e+09      4.000000      0.000000\n",
       "75%    1.448064e+09      5.000000      1.098612\n",
       "max    1.537142e+09      5.000000      7.799753"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory data analysis and missing values imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the range and distribution of log_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"log_votes\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.799753318287247"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"log_votes\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZq0lEQVR4nO3df5BV5Z3n8fdH8HdiwNhxWcDBmaEyIdYETQfZcXfWQUfBZIRsxVms2UhZ7pDN4q7uTO2Iqa01v9jSqknMuGvcYQIjOomEaByZBIcQf0w2VVFolKiILj3oSAsr7eDPmOhAPvvHfdrcNLe7Lwfuvd3yeVXd6nO+53nufQ4F/eGc89xzZJuIiIgqjur0ACIiYuxKiERERGUJkYiIqCwhEhERlSVEIiKisvGdHkC7nXLKKZ42bVqnhxERMaZs3rz5Rdtdg+tHXIhMmzaNnp6eTg8jImJMkfQPjeo5nRUREZUlRCIiorKESEREVJYQiYiIyloeIpLGSXpU0nfK+umSHpa0XdI3JR1T6seW9d6yfVrde1xb6k9LurCuPrfUeiUtbfW+RETEL2vHkchVwLa69RuAG21PB14Crij1K4CXbP86cGNph6QZwELgg8Bc4KslmMYBNwPzgBnApaVtRES0SUtDRNIU4KPA18q6gDnAnaXJKmBBWZ5f1inbzyvt5wOrbb9p+xmgF5hVXr22d9h+C1hd2kZERJu0+kjkK8CfAD8v6+8FXra9r6z3AZPL8mRgJ0DZ/kpp/3Z9UJ+h6geQtFhSj6Se/v7+Q92niIgoWhYikj4G7LG9ub7coKlH2Haw9QOL9nLb3ba7u7oO+MJlRERU1MpvrJ8DXCzpIuA44CRqRyYTJI0vRxtTgF2lfR8wFeiTNB54D7C3rj6gvs9Q9ZaYtvS7rXz7IT17/Uc78rkRESNp2ZGI7WttT7E9jdqF8ftt/wHwAPCJ0mwRcE9ZXlvWKdvvd+2xi2uBhWX21unAdGAjsAmYXmZ7HVM+Y22r9iciIg7UiXtnXQOslvRF4FFgRamvAG6X1EvtCGQhgO2tktYATwL7gCW29wNIuhJYD4wDVtre2tY9iYg4wrUlRGw/CDxYlndQm1k1uM3PgEuG6L8MWNagvg5YdxiHGhERByHfWI+IiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFSWEImIiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFSWEImIiMpaFiKSjpO0UdKPJW2V9LlSv1XSM5K2lNfMUpekmyT1SnpM0ll177VI0vbyWlRX/7Ckx0ufmySpVfsTEREHauXjcd8E5th+XdLRwA8l3Vu2/Vfbdw5qPw+YXl5nA7cAZ0s6GbgO6AYMbJa01vZLpc1i4CFqj8mdC9xLRES0RcuORFzzelk9urw8TJf5wG2l30PABEmTgAuBDbb3luDYAMwt206y/SPbBm4DFrRqfyIi4kAtvSYiaZykLcAeakHwcNm0rJyyulHSsaU2GdhZ172v1Iar9zWoNxrHYkk9knr6+/sPeb8iIqKmpSFie7/tmcAUYJakM4Brgd8APgKcDFxTmje6nuEK9UbjWG6723Z3V1fXQe5FREQMpS2zs2y/DDwIzLW9u5yyehP4S2BWadYHTK3rNgXYNUJ9SoN6RES0SStnZ3VJmlCWjwfOB54q1zIoM6kWAE+ULmuBy8osrdnAK7Z3A+uBCyRNlDQRuABYX7a9Jml2ea/LgHtatT8REXGgVs7OmgSskjSOWlitsf0dSfdL6qJ2OmoL8B9K+3XARUAv8AZwOYDtvZK+AGwq7T5ve29Z/jRwK3A8tVlZmZkVEdFGLQsR248BZzaozxmivYElQ2xbCaxsUO8Bzji0kUZERFX5xnpERFSWEImIiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFSWEImIiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFTWymesHydpo6QfS9oq6XOlfrqkhyVtl/RNSceU+rFlvbdsn1b3XteW+tOSLqyrzy21XklLW7UvERHRWCuPRN4E5tj+EDATmCtpNnADcKPt6cBLwBWl/RXAS7Z/HbixtEPSDGAh8EFgLvBVSePKs9tvBuYBM4BLS9uIiGiTloWIa14vq0eXl4E5wJ2lvgpYUJbnl3XK9vMkqdRX237T9jNALzCrvHpt77D9FrC6tI2IiDZp6TWRcsSwBdgDbAD+HnjZ9r7SpA+YXJYnAzsByvZXgPfW1wf1GaoeERFt0tIQsb3f9kxgCrUjhw80alZ+aohtB1s/gKTFknok9fT394888IiIaEpbZmfZfhl4EJgNTJA0vmyaAuwqy33AVICy/T3A3vr6oD5D1Rt9/nLb3ba7u7q6DscuRUQErZ2d1SVpQlk+Hjgf2AY8AHyiNFsE3FOW15Z1yvb7bbvUF5bZW6cD04GNwCZgepntdQy1i+9rW7U/ERFxoPEjN6lsErCqzKI6Clhj+zuSngRWS/oi8CiworRfAdwuqZfaEchCANtbJa0BngT2AUts7weQdCWwHhgHrLS9tYX7ExERg7QsRGw/BpzZoL6D2vWRwfWfAZcM8V7LgGUN6uuAdYc82IiIqCTfWI+IiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFSWEImIiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFSWEImIiMpa+Yz1qZIekLRN0lZJV5X6ZyU9L2lLeV1U1+daSb2SnpZ0YV19bqn1SlpaVz9d0sOStkv6ZnnWekREtElTISLpjArvvQ/4Y9sfAGYDSyTNKNtutD2zvNaVz5hB7bnqHwTmAl+VNK48o/1mYB4wA7i07n1uKO81HXgJuKLCOCMioqJmj0T+t6SNkv6jpAnNdLC92/YjZfk1YBsweZgu84HVtt+0/QzQS+1Z7LOAXts7bL8FrAbmSxIwB7iz9F8FLGhyfyIi4jBoKkRs/0vgD4CpQI+kb0j63WY/RNI04Ezg4VK6UtJjklZKmlhqk4Gddd36Sm2o+nuBl23vG1SPiIg2afqaiO3twH8DrgH+NXCTpKck/Zvh+kl6F3AXcLXtV4FbgF8DZgK7gS8NNG30sRXqjcawWFKPpJ7+/v7hhhsREQeh2WsivynpRmqnpOYAv1eudcwBbhym39HUAuTrtr8NYPsF2/tt/xz4C2qnq6B2JDG1rvsUYNcw9ReBCZLGD6ofwPZy2922u7u6uprZ5YiIaEKzRyL/C3gE+JDtJXXXOnZROzo5QLlmsQLYZvvLdfVJdc0+DjxRltcCCyUdK+l0YDqwEdgETC8zsY6hdvF9rW0DDwCfKP0XAfc0uT8REXEYjB+5CQAXAT+1vR9A0lHAcbbfsH37EH3OAT4JPC5pS6l9htrsqpnUTj09C3wKwPZWSWuAJ6nN7FpS93lXAuuBccBK21vL+10DrJb0ReBRaqEVERFt0myIfB84H3i9rJ8AfA/4raE62P4hja9brBumzzJgWYP6ukb9bO/gF6fDIiKizZo9nXWc7YEAoSyf0JohRUTEWNFsiPxE0lkDK5I+DPy0NUOKiIixotnTWVcD35I0MPtpEvBvWzOkiIgYK5oKEdubJP0G8H5q1zmesv1PLR1ZRESMes0eiQB8BJhW+pwpCdu3tWRUERExJjQVIpJup/Yt8y3A/lI2kBCJiDiCNXsk0g3MKF/wi4iIAJqfnfUE8M9aOZCIiBh7mj0SOQV4UtJG4M2Bou2LWzKqiIgYE5oNkc+2chARETE2NTvF9+8k/Qow3fb3JZ1A7T5WERFxBGv2VvB/SO0Jgn9eSpOBv27VoCIiYmxo9sL6Emp35X0V3n5A1ftaNaiIiBgbmg2RN8vzzQEoD4LKdN+IiCNcsyHyd5I+Axxfnq3+LeBvWjesiIgYC5oNkaVAP/A4tYdIrWOIJxpGRMSRo9nZWQPPQ/+L1g4nIiLGkmZnZz0jacfg1wh9pkp6QNI2SVslXVXqJ0vaIGl7+Tmx1CXpJkm9kh4b9PySRaX9dkmL6uoflvR46XNTea57RES0SbOns7qp3cX3I8C/Am4C/mqEPvuAP7b9AWA2sETSDGqnxu6zPR24r6wDzAOml9di4BaohQ5wHXA2tUfhXjcQPKXN4rp+c5vcn4iIOAyaChHb/1j3et72V4A5I/TZbfuRsvwasI3a90vmA6tKs1XAgrI8H7jNNQ8BEyRNAi4ENtjea/slYAMwt2w7yfaPyo0hb6t7r4iIaINmbwV/Vt3qUdSOTN7d7IdImgacCTwMnGp7N9SCRtLA900mAzvruvWV2nD1vgb1iIhok2bvnfWluuV9wLPA7zfTUdK7gLuAq22/Osxli0YbXKHeaAyLqZ324rTTThtpyBER0aRmZ2f9TpU3l3Q0tQD5uu1vl/ILkiaVo5BJwJ5S7wOm1nWfAuwq9XMH1R8s9SkN2jca/3JgOUB3d3e+JBkRcZg0ezrrj4bbbvvLDfoIWAFsG7R9LbAIuL78vKeufqWk1dQuor9SgmY98D/qLqZfAFxre6+k1yTNpnaa7DLgfzazPxERcXgczJMNP0LtFz3A7wE/4JevVQx2DvBJ4HFJW0rtM9TCY42kK4DngEvKtnXARUAv8AZwOUAJiy8Am0q7z9veW5Y/DdwKHA/cW14REdEmB/NQqrPKLCskfRb4lu1/P1QH2z+k8XULgPMatDe1Gz02eq+VwMoG9R7gjJEGHxERrdHs90ROA96qW38LmHbYRxMREWNKs0citwMbJd1NbQbUx6l9LyMiIo5gzc7OWibpXmrfVge43PajrRtWRESMBc2ezgI4AXjV9p8BfZJOb9GYIiJijGj2BozXAdcA15bS0Yx876yIiHiHa/ZI5OPAxcBPAGzv4iBuexIREe9MzYbIW2UKrgEkndi6IUVExFjRbIiskfTn1O6s+4fA98kDqiIijnjNzs760/Js9VeB9wP/3faGlo4sIiJGvRFDRNI4YL3t86k9yyMiIgJo4nSW7f3AG5Le04bxRETEGNLsN9Z/Ru1GihsoM7QAbP/nlowqIiLGhGZD5LvlFRER8bZhQ0TSabafs71quHYREXFkGumayF8PLEi6q8VjiYiIMWakEKl/HsivtnIgEREx9owUIh5iOSIiYsQQ+ZCkVyW9BvxmWX61PNv81eE6SlopaY+kJ+pqn5X0vKQt5XVR3bZrJfVKelrShXX1uaXWK2lpXf10SQ9L2i7pm5KOOfjdj4iIQzFsiNgeZ/sk2++2Pb4sD6yfNMJ73wrMbVC/0fbM8loHIGkGsBD4YOnzVUnjyhcdbwbmATOAS0tbgBvKe00HXgKuaG6XIyLicDmY54kcFNs/APY22Xw+sNr2m7afAXqBWeXVa3uH7beA1cB8SQLmAHeW/quABYd1ByIiYkQtC5FhXCnpsXK6a2KpTQZ21rXpK7Wh6u8FXra9b1A9IiLaqN0hcgvwa8BMYDfwpVJXg7auUG9I0mJJPZJ6+vv7D27EERExpLaGiO0XbO+3/XNqt5KfVTb1AVPrmk4Bdg1Tf5HabenHD6oP9bnLbXfb7u7q6jo8OxMREe0NEUmT6lY/DgzM3FoLLJR0bHl2+3RgI7AJmF5mYh1D7eL72vKArAeAT5T+i4B72rEPERHxC83eO+ugSboDOBc4RVIfcB1wrqSZ1E49PQt8CsD2VklrgCeBfcCScvdgJF0JrAfGASttby0fcQ2wWtIXgUeBFa3al4iIaKxlIWL70gblIX/R214GLGtQXwesa1DfwS9Oh0VERAd0YnZWRES8QyREIiKisoRIRERUlhCJiIjKEiIREVFZQiQiIipLiERERGUJkYiIqCwhEhERlSVEIiKisoRIRERUlhCJiIjKEiIREVFZQiQiIipLiERERGUJkYiIqCwhEhERlSVEIiKispaFiKSVkvZIeqKudrKkDZK2l58TS12SbpLUK+kxSWfV9VlU2m+XtKiu/mFJj5c+N0lSq/YlIiIaa+WRyK3A3EG1pcB9tqcD95V1gHnA9PJaDNwCtdABrgPOpvY89esGgqe0WVzXb/BnRUREi7UsRGz/ANg7qDwfWFWWVwEL6uq3ueYhYIKkScCFwAbbe22/BGwA5pZtJ9n+kW0Dt9W9V0REtEm7r4mcans3QPn5vlKfDOysa9dXasPV+xrUG5K0WFKPpJ7+/v5D3omIiKgZLRfWG13PcIV6Q7aX2+623d3V1VVxiBERMVi7Q+SFciqK8nNPqfcBU+vaTQF2jVCf0qAeERFt1O4QWQsMzLBaBNxTV7+szNKaDbxSTnetBy6QNLFcUL8AWF+2vSZpdpmVdVnde0VERJuMb9UbS7oDOBc4RVIftVlW1wNrJF0BPAdcUpqvAy4CeoE3gMsBbO+V9AVgU2n3edsDF+s/TW0G2PHAveUVERFt1LIQsX3pEJvOa9DWwJIh3mclsLJBvQc441DGGBERh2a0XFiPiIgxKCESERGVJUQiIqKyhEhERFSWEImIiMoSIhERUVlCJCIiKkuIREREZQmRiIioLCESERGVJUQiIqKyhEhERFSWEImIiMpadhffOHymLf1uxz772es/2rHPjojRL0ciERFRWUIkIiIqS4hERERlHQkRSc9KelzSFkk9pXaypA2StpefE0tdkm6S1CvpMUln1b3PotJ+u6RFQ31eRES0RicvrP+O7Rfr1pcC99m+XtLSsn4NMA+YXl5nA7cAZ0s6mdpz27sBA5slrbX9Ujt34p2uUxf1c0E/YmwYTaez5gOryvIqYEFd/TbXPARMkDQJuBDYYHtvCY4NwNx2Dzoi4kjWqRAx8D1JmyUtLrVTbe8GKD/fV+qTgZ11fftKbaj6ASQtltQjqae/v/8w7kZExJGtU6ezzrG9S9L7gA2SnhqmrRrUPEz9wKK9HFgO0N3d3bBNREQcvI4cidjeVX7uAe4GZgEvlNNUlJ97SvM+YGpd9ynArmHqERHRJm0PEUknSnr3wDJwAfAEsBYYmGG1CLinLK8FLiuztGYDr5TTXeuBCyRNLDO5Lii1iIhok06czjoVuFvSwOd/w/bfStoErJF0BfAccElpvw64COgF3gAuB7C9V9IXgE2l3edt723fbkRERNtDxPYO4EMN6v8InNegbmDJEO+1Elh5uMcYERHNGU1TfCMiYoxJiERERGUJkYiIqCwhEhERlSVEIiKisoRIRERUlhCJiIjKEiIREVFZJ58nEjGkTj3HBPIsk4iDkSORiIioLCESERGVJUQiIqKyhEhERFSWEImIiMoSIhERUVmm+EYM0qnpxZlaHGNRjkQiIqKyMR8ikuZKelpSr6SlnR5PRMSRZEyfzpI0DrgZ+F2gD9gkaa3tJzs7soiDl2/px1g0pkMEmAX0lue2I2k1MB9IiEQchFwHiqrGeohMBnbWrfcBZw9uJGkxsLisvi7p6YqfdwrwYsW+rZaxVZOxVXNYxqYbDsNIDvSO/3NrkZHG9iuNimM9RNSg5gMK9nJg+SF/mNRju/tQ36cVMrZqMrZqMrZq3oljG+sX1vuAqXXrU4BdHRpLRMQRZ6yHyCZguqTTJR0DLATWdnhMERFHjDF9Osv2PklXAuuBccBK21tb+JGHfEqshTK2ajK2ajK2at5xY5N9wCWEiIiIpoz101kREdFBCZGIiKgsIdKE0XxrFUkrJe2R9ESnxzKYpKmSHpC0TdJWSVd1ekwDJB0naaOkH5exfa7TY6onaZykRyV9p9NjGUzSs5Iel7RFUk+nx1NP0gRJd0p6qvy9+xedHhOApPeXP6+B16uSru70uAZI+i/l38ETku6QdFzTfXNNZHjl1ir/l7pbqwCXjpZbq0j6beB14DbbZ3R6PPUkTQIm2X5E0ruBzcCC0fBnJ0nAibZfl3Q08EPgKtsPdXhoAEj6I6AbOMn2xzo9nnqSngW6bY+6L81JWgX8H9tfKzM2T7D9cqfHVa/8TnkeONv2P4yC8Uym9vd/hu2fSloDrLN9azP9cyQysrdvrWL7LWDg1iqjgu0fAHs7PY5GbO+2/UhZfg3YRu0uAx3nmtfL6tHlNSr+RyVpCvBR4GudHstYIukk4LeBFQC23xptAVKcB/z9aAiQOuOB4yWNB07gIL5vlxAZWaNbq4yKX4RjiaRpwJnAw50dyS+UU0ZbgD3ABtujZWxfAf4E+HmnBzIEA9+TtLncUmi0+FWgH/jLcirwa5JO7PSgGlgI3NHpQQyw/Tzwp8BzwG7gFdvfa7Z/QmRkTd1aJYYm6V3AXcDVtl/t9HgG2N5veya1Ox3MktTx04GSPgbssb2502MZxjm2zwLmAUvKKdXRYDxwFnCL7TOBnwCj7RrmMcDFwLc6PZYBkiZSO7tyOvDPgRMl/btm+ydERpZbqxyCcr3hLuDrtr/d6fE0Uk55PAjM7fBQAM4BLi7XHVYDcyT9VWeH9Mts7yo/9wB3UzvlOxr0AX11R5R3UguV0WQe8IjtFzo9kDrnA8/Y7rf9T8C3gd9qtnNCZGS5tUpF5eL1CmCb7S93ejz1JHVJmlCWj6f2D+mpzo4KbF9re4rtadT+rt1vu+n/FbaapBPLJAnKqaILgFExM9D2/wN2Snp/KZ3H6HssxKWMolNZxXPAbEknlH+z51G7ftmUMX3bk3bowK1VDoqkO4BzgVMk9QHX2V7R2VG97Rzgk8Dj5doDwGdsr+vgmAZMAlaVmTJHAWtsj7rptKPQqcDdtd81jAe+YftvOzukX/KfgK+X//DtAC7v8HjeJukEarM8P9XpsdSz/bCkO4FHgH3AoxzELVAyxTciIirL6ayIiKgsIRIREZUlRCIiorKESEREVJYQiYiIyhIiERFRWUIkIiIq+/+UE1chWtGU0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"log_votes\"].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of missing values for each columm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    6\n",
      "summary       7\n",
      "verified      0\n",
      "time          0\n",
      "rating        0\n",
      "log_votes     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill-in the missing values for reviewText below. We will just use the placeholder \"Missing\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reviewText\"].fillna(\"Missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stop word removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\solharsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\solharsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the stop word removal and text cleaning processes below. NLTK library provides a list of common stop words. We will use the list, but remove some of the words from that list (because those words are actually useful to understand the sentiment in the sentence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", \n",
    "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
    "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [word for word in stop if word not in excluding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(texts): \n",
    "    final_text_list=[]\n",
    "    for sent in texts:\n",
    "        filtered_sentence=[]\n",
    "        sent = sent.lower() # Lowercase \n",
    "        sent = sent.strip() # Remove leading/trailing whitespace\n",
    "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
    "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
    "        for w in word_tokenize(sent):\n",
    "            # We are applying some custom filtering here, feel free to try different things\n",
    "            # Check if it is not numeric and its length>2 and not in stop words\n",
    "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop_words):  \n",
    "                # Stem and add to filtered list\n",
    "                filtered_sentence.append(snow.stem(w))\n",
    "        final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
    "        final_text_list.append(final_string)\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing the reviewText field\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-processing the reviewText field\")\n",
    "df[\"reviewText\"] = process_text(df[\"reviewText\"].tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scaling numerical fields:\n",
    "We will apply min-max scaling to our rating field so that they will be between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rating\"] = (df[\"rating\"] - df[\"rating\"].min())/(df[\"rating\"].max()-df[\"rating\"].min())\n",
    "df[\"time\"] = (df[\"time\"] - df[\"time\"].min())/(df[\"time\"].max()-df[\"time\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Splitting the training dataset into training and validation\n",
    "Sklearn library has a useful function to split datasets. We will use the train_test_split() function. In the example below, we get 90% of the data for training and 10% is left for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# Input: \"reviewText\", \"rating\" and \"time\"\n",
    "# Target: \"log_votes\"\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[[\"reviewText\", \"rating\", \"time\"]],\n",
    "                                                  df[\"log_votes\"].tolist(),\n",
    "                                                  test_size=0.10,\n",
    "                                                  shuffle=True\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Computing Bag of Words Features\n",
    "\n",
    "We are using binary features here. TF and TF-IDF are other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# Initialize the binary count vectorizer\n",
    "tfidf_vectorizer = CountVectorizer(binary=True,\n",
    "                                   max_features=50 # Limit the vocabulary size\n",
    "                                  )\n",
    "# Fit and transform\n",
    "X_train_text_vectors = tfidf_vectorizer.fit_transform(X_train[\"reviewText\"].tolist())\n",
    "# Only transform\n",
    "X_val_text_vectors = tfidf_vectorizer.transform(X_val[\"reviewText\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not': 23, 'softwar': 33, 'get': 11, 'back': 1, 'realli': 30, 'find': 10, 'need': 21, 'help': 14, 'well': 45, 'mani': 19, 'great': 13, 'problem': 26, 'download': 6, 'version': 42, 'still': 34, 'good': 12, 'one': 24, 'instal': 15, 'window': 46, 'work': 47, 'way': 44, 'use': 39, 'product': 27, 'comput': 4, 'support': 35, 'recommend': 31, 'like': 16, 'want': 43, 'program': 28, 'user': 40, 'year': 49, 'much': 20, 'could': 5, 'would': 48, 'file': 9, 'easi': 7, 'even': 8, 'make': 18, 'also': 0, 'look': 17, 'better': 2, 'time': 36, 'new': 22, 'upgrad': 38, 'tri': 37, 've': 41, 'run': 32, 'buy': 3, 'price': 25, 'purchas': 29}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge our features to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_features = np.column_stack((X_train_text_vectors.toarray(), \n",
    "                                    X_train[\"rating\"].values, \n",
    "                                    X_train[\"time\"].values))\n",
    "X_val_features = np.column_stack((X_val_text_vectors.toarray(), \n",
    "                                  X_val[\"rating\"].values,\n",
    "                                  X_val[\"time\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Fitting tree-based regressors and checking the validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor\n",
    "\n",
    "Let's first fit a DecisionTreeRegressor from Sklearn library, and check the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor on Validation: Mean_squared_error: 0.671350, R_square_score: 0.301933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "dtRegressor = DecisionTreeRegressor(max_depth = 10,\n",
    "                                    min_samples_leaf = 15)\n",
    "dtRegressor.fit(X_train_features, y_train)\n",
    "dtRegressor_val_predictions = dtRegressor.predict(X_val_features)\n",
    "print(\"DecisionTreeRegressor on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, dtRegressor_val_predictions), r2_score(y_val, dtRegressor_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor\n",
    "\n",
    "Let's now fit a RandomForestRegressor from Sklearn library, and check the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor on Validation: Mean_squared_error: 0.601390, R_square_score: 0.374678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "rfRegressor = RandomForestRegressor(n_estimators = 200,\n",
    "                                    max_depth = 10,\n",
    "                                    min_samples_leaf = 15)\n",
    "rfRegressor.fit(X_train_features, y_train)\n",
    "rfRegressor_val_predictions =rfRegressor.predict(X_val_features)\n",
    "print(\"RandomForestRegressor on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, rfRegressor_val_predictions), r2_score(y_val, rfRegressor_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Let's try different parameter values and see how the DecisionTreeRegressor model performs under some combinations of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   52.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 10, 'min_samples_leaf': 35}\n",
      "Best score:  -0.6259033641867322\n",
      "DecisionTreeRegressor with GridSearchCV on Validation: Mean_squared_error: 0.650712, R_square_score: 0.323393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    " \n",
    "dt = DecisionTreeRegressor()\n",
    "parameters = {'max_depth': [10, 20, 30, 40],\n",
    "              'min_samples_leaf': [5, 15, 25, 35]}\n",
    "                     \n",
    "# NOTE: GridSearchCV uses by default the score function of the estimator to evaluate \n",
    "# (r2_score for regression; accuracy_score for classification). If desired, \n",
    "# other scoring functions can be specified via the 'scoring' parameter. \n",
    "\n",
    "regressor_grid = GridSearchCV(dt,\n",
    "                              parameters,\n",
    "                              cv=5,\n",
    "                              verbose=1,\n",
    "                              #n_jobs=-1,\n",
    "                              scoring = 'neg_mean_squared_error')\n",
    "regressor_grid.fit(X_train_features, y_train)\n",
    "print(\"Best parameters: \", regressor_grid.best_params_)\n",
    "print(\"Best score: \", regressor_grid.best_score_)\n",
    "regressor_grid_val_predictions = regressor_grid.best_estimator_.predict(X_val_features)\n",
    "print(\"DecisionTreeRegressor with GridSearchCV on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, regressor_grid_val_predictions), r2_score(y_val, regressor_grid_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'min_samples_leaf': 35, 'max_depth': 10}\n",
      "Best score:  -0.6259033641867322\n",
      "DecisionTreeRegressor with RandomizedSearchCV on Validation: Mean_squared_error: 0.650712, R_square_score: 0.323393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "dt = DecisionTreeRegressor()\n",
    "parameters = {'max_depth': [10, 20, 30, 40],\n",
    "              'min_samples_leaf': [5, 15, 25, 35]}\n",
    "# NOTE: RandomizedSearchCV uses by default the score function of the estimator to evaluate\n",
    "# (r2_score for regression; accuracy_score for classification). \n",
    "# If desired, other scoring functions can be specified via the 'scoring' parameter.\n",
    "# NOTE: You can also experiment with different n_iter \n",
    "# (number of parameter settings that are sampled by the RandomizedSearch), default = 10\n",
    "regressor_rand = RandomizedSearchCV(dt,\n",
    "                                    parameters,\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    #n_jobs=-1,\n",
    "                                    scoring = 'neg_mean_squared_error')\n",
    "regressor_rand.fit(X_train_features, y_train)\n",
    "print(\"Best parameters: \", regressor_rand.best_params_)\n",
    "print(\"Best score: \", regressor_rand.best_score_)\n",
    "regressor_rand_val_predictions = regressor_rand.best_estimator_.predict(X_val_features)\n",
    "print(\"DecisionTreeRegressor with RandomizedSearchCV on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, regressor_rand_val_predictions), r2_score(y_val, regressor_rand_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning: Always a good idea to try other parameter ranges and/or combinations of parameters. If training time is a priority, we can try RandomizedSearchCV instead of GridSearchCV, it's much faster and with almost as good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
