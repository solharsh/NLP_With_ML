{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Classifier_Predicting_Human_Safety_Tag_Text.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMG9jCq/4Ts4wthp8Rzc1C2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solharsh/NLP_With_ML/blob/master/KNN_Classifier_Predicting_Human_Safety_Tag_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNAZyRZIrOdO",
        "colab_type": "text"
      },
      "source": [
        "K Nearest Neighbors Model for the Product Safety Dataset\n",
        "\n",
        "In this notebook, I will be using the K Nearest Neighbors method to build a classifier to predict the predict the human_tag field of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfFS5Dw3rO_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9jAN6E1rZeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(r\"/content/training(1).csv\",encoding='utf-8', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ithJgRUQrpvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ff164b92-1587-4212-ce17-c423e739934e"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>title</th>\n",
              "      <th>human_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47490</td>\n",
              "      <td>15808037321</td>\n",
              "      <td>I ordered a sample of the Dietspotlight Burn, ...</td>\n",
              "      <td>6/25/2018 17:51</td>\n",
              "      <td>1</td>\n",
              "      <td>DO NOT BUY!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16127</td>\n",
              "      <td>16042300811</td>\n",
              "      <td>This coffee tasts terrible as if it got burnt ...</td>\n",
              "      <td>2/8/2018 15:59</td>\n",
              "      <td>2</td>\n",
              "      <td>Coffee not good</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51499</td>\n",
              "      <td>16246716471</td>\n",
              "      <td>I've been buying lightly salted Planters cashe...</td>\n",
              "      <td>3/22/2018 17:53</td>\n",
              "      <td>2</td>\n",
              "      <td>Poor Quality - Burnt, Shriveled Nuts With Blac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36725</td>\n",
              "      <td>14460351031</td>\n",
              "      <td>This product is great in so many ways. It goes...</td>\n",
              "      <td>12/7/2017 8:49</td>\n",
              "      <td>4</td>\n",
              "      <td>Very lovey product, good sunscreen, but strong...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49041</td>\n",
              "      <td>15509997211</td>\n",
              "      <td>My skin did not agree with this product, it wo...</td>\n",
              "      <td>3/21/2018 13:51</td>\n",
              "      <td>1</td>\n",
              "      <td>Not for everyone. Reactions can be harsh.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  ...  human_tag\n",
              "0  47490  ...          0\n",
              "1  16127  ...          0\n",
              "2  51499  ...          0\n",
              "3  36725  ...          0\n",
              "4  49041  ...          1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nugxicuGrtiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "434ecab4-3b37-4bb4-a621-67e64d9391a5"
      },
      "source": [
        "test_df = pd.read_csv(r\"/content/public_test_features(1).csv\",encoding='utf-8',header=0)\n",
        "test_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62199</td>\n",
              "      <td>15449606311</td>\n",
              "      <td>Quality of material is great, however, the bac...</td>\n",
              "      <td>3/7/2018 19:47</td>\n",
              "      <td>3</td>\n",
              "      <td>great backpack with strange fit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76123</td>\n",
              "      <td>15307152511</td>\n",
              "      <td>The product was okay but wasn't refined campho...</td>\n",
              "      <td>43135.875</td>\n",
              "      <td>2</td>\n",
              "      <td>Not refined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>78742</td>\n",
              "      <td>12762748321</td>\n",
              "      <td>I normally read the reviews before buying some...</td>\n",
              "      <td>42997.37708</td>\n",
              "      <td>1</td>\n",
              "      <td>Doesnt work, wouldnt recommend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64010</td>\n",
              "      <td>15936405041</td>\n",
              "      <td>These pads are completely worthless. The light...</td>\n",
              "      <td>43313.25417</td>\n",
              "      <td>1</td>\n",
              "      <td>The lighter colored side of the pads smells li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17058</td>\n",
              "      <td>13596875291</td>\n",
              "      <td>The saw works great but the blade oiler does n...</td>\n",
              "      <td>12/5/2017 20:17</td>\n",
              "      <td>2</td>\n",
              "      <td>The saw works great but the blade oiler does n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  ...                                              title\n",
              "0  62199  ...                    great backpack with strange fit\n",
              "1  76123  ...                                        Not refined\n",
              "2  78742  ...                     Doesnt work, wouldnt recommend\n",
              "3  64010  ...  The lighter colored side of the pads smells li...\n",
              "4  17058  ...  The saw works great but the blade oiler does n...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DvDo7rMrz3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "3a1425a3-820d-4910-ce66-1e7cd2c639b9"
      },
      "source": [
        "print(train_df.isna().sum())\n",
        "print(test_df.isna().sum())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID             0\n",
            "doc_id         0\n",
            "text           6\n",
            "date           0\n",
            "star_rating    0\n",
            "title          1\n",
            "human_tag      0\n",
            "dtype: int64\n",
            "ID             0\n",
            "doc_id         0\n",
            "text           2\n",
            "date           0\n",
            "star_rating    0\n",
            "title          1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "727Eqkcyr6QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's fill-in the missing values for text below. We will just use the placeholder \"Missing\" here.\n",
        "\n",
        "train_df['text'].fillna(\"Missing\", inplace=True)\n",
        "test_df['text'].fillna(\"Missing\", inplace=True)\n",
        "train_df['title'].fillna(\"Missing\", inplace=True)\n",
        "test_df['title'].fillna(\"Missing\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8IyLHWRr_dE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e8fce2f0-e9a0-46a8-8c12-161f469b0994"
      },
      "source": [
        "#Now, it is time to process the text fields. We will remove stop words and apply stemming.\n",
        "\n",
        "print('The shape of the training dataset is:', train_df.shape)\n",
        "print('The shape of the test dataset is:', test_df.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the training dataset is: (63134, 7)\n",
            "The shape of the test dataset is: (15784, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xVICeoqsB2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9987f2ed-1e65-4915-bd26-e6fde5fefd85"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_df[\"human_tag\"].plot.hist()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAUTUlEQVR4nO3df5Bd9Xnf8fcHBAYnYMBgykikwo0SR8G/sIyVSdLEpgEBCbiNQ6FxURgGdQLuJE2mNXYzxbXDjJk2JqF17ChBY0HqAHbqoMZQVcE4nnYqYDEOvxzKBoORjI2CMCTBhmA//eN+BddiVzo6u/euLvt+zdzZc57zPfc+XyTmo/Pjnk1VIUlSHwcsdAOSpMlliEiSejNEJEm9GSKSpN4MEUlSb0sWuoFxO/roo2v58uUL3YYkTYw777zzr6vqmJm2LboQWb58OVNTUwvdhiRNjCSPzLbN01mSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4W3TfW52L5pZ9dkM99+MNnLsjnStLeeCQiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSeptpCGS5OEk9yT5UpKpVjsqyZYkD7afR7Z6klyVZDrJ3UlOGnqftW38g0nWDtXf0t5/uu2bUc5HkvS9xnEk8vaqelNVrWrrlwK3VNUK4Ja2DnA6sKK91gEfg0HoAJcBbwNOBi7bFTxtzEVD+60Z/XQkSbssxOmss4GNbXkj8M6h+jU1sBU4IslxwGnAlqraWVVPAluANW3b4VW1taoKuGbovSRJYzDqECngfyW5M8m6Vju2qh5ry18Hjm3LS4FHh/bd1mp7qm+bof4SSdYlmUoytWPHjrnMR5I0ZNRP8f2Jqtqe5DXAliR/ObyxqipJjbgHqmo9sB5g1apVI/88SVosRnokUlXb28/Hgc8wuKbxjXYqivbz8TZ8O3D80O7LWm1P9WUz1CVJYzKyEEnyfUkO27UMnArcC2wCdt1htRa4sS1vAs5vd2mtBp5qp702A6cmObJdUD8V2Ny2PZ1kdbsr6/yh95IkjcEoT2cdC3ym3XW7BPhkVf3PJHcANyS5EHgEOKeNvwk4A5gGngEuAKiqnUk+BNzRxn2wqna25YuBTwCHAje3lyRpTEYWIlX1EPDGGepPAKfMUC/gklneawOwYYb6FHDinJuVJPXiN9YlSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLU28hDJMmBSe5K8qdt/YQktyWZTnJ9koNb/RVtfbptXz70Hu9r9QeSnDZUX9Nq00kuHfVcJEnfaxxHIr8CfHlo/Qrgyqr6QeBJ4MJWvxB4stWvbONIshI4F/hRYA3wuy2YDgQ+CpwOrATOa2MlSWMy0hBJsgw4E/iDth7gHcCn25CNwDvb8tltnbb9lDb+bOC6qnq2qr4CTAMnt9d0VT1UVc8B17WxkqQxGfWRyG8D/w74blt/NfDNqnq+rW8DlrblpcCjAG37U238C/Xd9pmtLkkak5GFSJKfBR6vqjtH9Rn70Mu6JFNJpnbs2LHQ7UjSy8Yoj0R+HDgrycMMTjW9A/gd4IgkS9qYZcD2trwdOB6gbX8V8MRwfbd9Zqu/RFWtr6pVVbXqmGOOmfvMJEnACEOkqt5XVcuqajmDC+Ofq6pfBG4F3tWGrQVubMub2jpt++eqqlr93Hb31gnACuB24A5gRbvb6+D2GZtGNR9J0kst2fuQefde4LokvwncBVzd6lcD1yaZBnYyCAWq6r4kNwD3A88Dl1TVdwCSvAfYDBwIbKiq+8Y6E0la5MYSIlX1eeDzbfkhBndW7T7m28AvzLL/5cDlM9RvAm6ax1YlSfvAb6xLknozRCRJvRkikqTeDBFJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvRkikqTeDBFJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvXUKkSSvH3UjkqTJ0/VI5HeT3J7k4iSvGmlHkqSJ0SlEquongV8EjgfuTPLJJD8z0s4kSfu9ztdEqupB4DeA9wI/BVyV5C+T/LNRNSdJ2r91vSbyhiRXAl8G3gH8XFX9SFu+coT9SZL2Y0s6jvsvwB8A76+qb+0qVtXXkvzGSDqTJO33uobImcC3quo7AEkOAA6pqmeq6tqRdSdJ2q91vSbyZ8ChQ+uvbDVJ0iLWNUQOqaq/3bXSll85mpYkSZOia4j8XZKTdq0keQvwrT2MlyQtAl2vifwq8KkkXwMC/APgn4+sK0nSROgUIlV1R5LXAT/cSg9U1d+Pri1J0iTYlwcwvhV4A3AScF6S8/c0OMkh7VEpf5HkviT/sdVPSHJbkukk1yc5uNVf0dan2/blQ+/1vlZ/IMlpQ/U1rTad5NJ9mIskaR50/bLhtcB/Bn6CQZi8FVi1l92eBd5RVW8E3gSsSbIauAK4sqp+EHgSuLCNvxB4stWvbONIshI4F/hRYA2D53gdmORA4KPA6cBKBsG2stOsJUnzous1kVXAyqqqrm/cxu66o+ug9ioG33L/F62+EfgA8DHg7LYM8GngvyZJq19XVc8CX0kyDZzcxk1X1UMASa5rY+/v2qMkaW66ns66l8HF9H3Sjhi+BDwObAH+CvhmVT3fhmwDlrblpcCjAG37U8Crh+u77TNbfaY+1iWZSjK1Y8eOfZ2GJGkWXY9EjgbuT3I7g9NUAFTVWXvaqX3D/U1JjgA+A7yub6NzUVXrgfUAq1at6nw0JUnas64h8oG5fEhVfTPJrcCPAUckWdKONpYB29uw7QweNb8tyRLgVcATQ/VdhveZrS5JGoOuv0/kz4GHgYPa8h3AF/e0T5Jj2hEISQ4FfobBU4BvBd7Vhq0FbmzLm9o6bfvn2nWVTcC57e6tE4AVwO2thxXtbq+DGVx839RlPpKk+dHpSCTJRcA64CjgHzG49vBx4JQ97HYcsLHdRXUAcENV/WmS+4HrkvwmcBdwdRt/NXBtu3C+k0EoUFX3JbmBwQXz54FLhh4E+R5gM3AgsKGq7us8c0nSnHU9nXUJgzuiboPBL6hK8po97VBVdwNvnqH+EC/eXTVc/zbwC7O81+XA5TPUbwJu6tC/JGkEut6d9WxVPbdrpV2z8AK1JC1yXUPkz5O8Hzi0/W71TwH/Y3RtSZImQdcQuRTYAdwD/CsGp5D8jYaStMh1fQDjd4Hfby9JkoDud2d9hRmugVTVa+e9I0nSxNiXZ2ftcgiDu6iOmv92JEmTpOuXDZ8Yem2vqt8Gzhxxb5Kk/VzX01knDa0ewODIpOtRjCTpZaprEPzW0PLzDB6Bcs68dyNJmihd7856+6gbkSRNnq6ns35tT9ur6iPz044kaZLsy91Zb+XFp+T+HIMn6T44iqYkSZOha4gsA06qqr8BSPIB4LNV9e5RNSZJ2v91fezJscBzQ+vPtZokaRHreiRyDXB7ks+09XcCG0fTkiRpUnS9O+vyJDcDP9lKF1TVXaNrS5I0CbqezgJ4JfB0Vf0Og9+DfsKIepIkTYhOIZLkMuC9wPta6SDgD0fVlCRpMnQ9EvmnwFnA3wFU1deAw0bVlCRpMnQNkeeqqmiPg0/yfaNrSZI0KbqGyA1Jfg84IslFwJ/hL6iSpEVvr3dnJQlwPfA64Gngh4H/UFVbRtybJGk/t9cQqapKclNVvR4wOCRJL+h6OuuLSd460k4kSROn6zfW3wa8O8nDDO7QCoODlDeMqjFJ0v5vjyGS5Aeq6qvAaWPqR5I0QfZ2JPInDJ7e+0iSP66qnx9HU5KkybC3ayIZWn7tKBuRJE2evYVIzbIsSdJeT2e9McnTDI5IDm3L8OKF9cNH2p0kab+2xyORqjqwqg6vqsOqaklb3rW+xwBJcnySW5Pcn+S+JL/S6kcl2ZLkwfbzyFZPkquSTCe5O8lJQ++1to1/MMnaofpbktzT9rmqfTFSkjQm+/Io+H31PPDrVbUSWA1ckmQlcClwS1WtAG5p6wCnAyvaax3wMRiEDnAZg9uMTwYu2xU8bcxFQ/utGeF8JEm7GVmIVNVjVfXFtvw3wJeBpcDZvPhbETcy+C2JtPo1NbCVwXO6jmNwe/GWqtpZVU8y+Nb8mrbt8Kra2h4Oec3Qe0mSxmCURyIvSLIceDNwG3BsVT3WNn2dF39X+1Lg0aHdtrXanurbZqjP9PnrkkwlmdqxY8ec5iJJetHIQyTJ9wN/DPxqVT09vG348fKjVFXrq2pVVa065phjRv1xkrRojDREkhzEIED+W1X991b+RjsVRfv5eKtvB44f2n1Zq+2pvmyGuiRpTEYWIu1OqauBL1fVR4Y2bQJ23WG1FrhxqH5+u0trNfBUO+21GTg1yZHtgvqpwOa27ekkq9tnnT/0XpKkMej6AMY+fhz4l8A9Sb7Uau8HPszgl1xdCDwCnNO23QScAUwDzwAXAFTVziQfAu5o4z5YVTvb8sXAJ4BDgZvbS5I0JiMLkar633zvY1OGnTLD+AIumeW9NgAbZqhPASfOoU1J0hyM5e4sSdLLkyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3kYWIkk2JHk8yb1DtaOSbEnyYPt5ZKsnyVVJppPcneSkoX3WtvEPJlk7VH9LknvaPlclyajmIkma2SiPRD4BrNmtdilwS1WtAG5p6wCnAyvaax3wMRiEDnAZ8DbgZOCyXcHTxlw0tN/unyVJGrGRhUhVfQHYuVv5bGBjW94IvHOofk0NbAWOSHIccBqwpap2VtWTwBZgTdt2eFVtraoCrhl6L0nSmIz7msixVfVYW/46cGxbXgo8OjRuW6vtqb5thvqMkqxLMpVkaseOHXObgSTpBUsW6oOrqpLUmD5rPbAeYNWqVWP5TEmayfJLP7sgn/vwh88cyfuO+0jkG+1UFO3n462+HTh+aNyyVttTfdkMdUnSGI07RDYBu+6wWgvcOFQ/v92ltRp4qp322gycmuTIdkH9VGBz2/Z0ktXtrqzzh95LkjQmIzudleSPgJ8Gjk6yjcFdVh8GbkhyIfAIcE4bfhNwBjANPANcAFBVO5N8CLijjftgVe26WH8xgzvADgVubi9J0hiNLESq6rxZNp0yw9gCLpnlfTYAG2aoTwEnzqVHSdLc+I11SVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6m/gQSbImyQNJppNcutD9SNJiMtEhkuRA4KPA6cBK4LwkKxe2K0laPCY6RICTgemqeqiqngOuA85e4J4kadFYstANzNFS4NGh9W3A23YflGQdsK6t/m2SB3p+3tHAX/fct7dcMe5P/B4LMucFttjmvNjmC4twzrliTnP+h7NtmPQQ6aSq1gPr5/o+SaaqatU8tDQxnPPL32KbLzjn+TTpp7O2A8cPrS9rNUnSGEx6iNwBrEhyQpKDgXOBTQvckyQtGhN9Oquqnk/yHmAzcCCwoaruG+FHzvmU2ARyzi9/i22+4JznTapqFO8rSVoEJv10liRpARkikqTeDJEZ7O1RKklekeT6tv22JMvH3+X86TDfX0tyf5K7k9ySZNZ7xidF18flJPn5JJVk4m8H7TLnJOe0P+v7knxy3D3Otw5/t38gya1J7mp/v89YiD7nS5INSR5Pcu8s25Pkqvbf4+4kJ835Q6vK19CLwQX6vwJeCxwM/AWwcrcxFwMfb8vnAtcvdN8jnu/bgVe25V+e5Pl2nXMbdxjwBWArsGqh+x7Dn/MK4C7gyLb+moXuewxzXg/8clteCTy80H3Pcc7/GDgJuHeW7WcANwMBVgO3zfUzPRJ5qS6PUjkb2NiWPw2ckiRj7HE+7XW+VXVrVT3TVrcy+D7OJOv6uJwPAVcA3x5ncyPSZc4XAR+tqicBqurxMfc437rMuYDD2/KrgK+Nsb95V1VfAHbuYcjZwDU1sBU4Islxc/lMQ+SlZnqUytLZxlTV88BTwKvH0t386zLfYRcy+JfMJNvrnNth/vFV9dlxNjZCXf6cfwj4oST/J8nWJGvG1t1odJnzB4B3J9kG3AT86/G0tmD29f/3vZro74lovJK8G1gF/NRC9zJKSQ4APgL80gK3Mm5LGJzS+mkGR5tfSPL6qvrmgnY1WucBn6iq30ryY8C1SU6squ8udGOTwiORl+ryKJUXxiRZwuAw+ImxdDf/Oj06Jsk/Af49cFZVPTum3kZlb3M+DDgR+HyShxmcO9404RfXu/w5bwM2VdXfV9VXgP/HIFQmVZc5XwjcAFBV/xc4hMHDGV+u5v1RUYbIS3V5lMomYG1bfhfwuWpXrSbQXueb5M3A7zEIkEk/Tw57mXNVPVVVR1fV8qpazuA60FlVNbUw7c6LLn+v/4TBUQhJjmZweuuhcTY5z7rM+avAKQBJfoRBiOwYa5fjtQk4v92ltRp4qqoem8sbejprNzXLo1SSfBCYqqpNwNUMDnunGVzEOnfhOp6bjvP9T8D3A59q9w98tarOWrCm56jjnF9WOs55M3BqkvuB7wD/tqom9Qi765x/Hfj9JP+GwUX2X5rgfxCS5I8Y/EPg6Had5zLgIICq+jiD6z5nANPAM8AFc/7MCf7vJUlaYJ7OkiT1ZohIknozRCRJvRkikqTeDBFJUm+GiCSpN0NEktTb/weVTjGUVqoEZQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NRV14nnsGUd",
        "colab_type": "text"
      },
      "source": [
        "Most of the values for the human tag are False. Meaning, they were identified as safe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofI2GKM0sD7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "c69aade2-524d-44e3-d00a-13aaac6b1681"
      },
      "source": [
        "# Install the library and functions\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMinPnoBsIYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk, re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGmc5c6tsK2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2ecd3c17-6f1e-4eb6-e1a5-ed596f568dcb"
      },
      "source": [
        "stop = stopwords.words(\"english\")\n",
        "print(stop)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysq5MGjksMb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These words are important for our problem. We don't want to remove them.\n",
        "excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
        "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", \n",
        "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
        "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
        "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wki6cEjWsOeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New stop word list\n",
        "stop_words = [word for word in stop if word not in excluding]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbUVj34_sQb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7d8c7f79-a908-4924-95cd-2e1f4070dda4"
      },
      "source": [
        "print(len(stop_words))\n",
        "print(len(stop))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "142\n",
            "179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsNZVEqhsToK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "snow = SnowballStemmer('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5lcXEhWsWDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_text(texts): \n",
        "    final_text_list=[]\n",
        "    for sent in texts:\n",
        "        filtered_sentence=[]\n",
        "        \n",
        "        sent = sent.lower() # Lowercase \n",
        "        sent = sent.strip() # Remove leading/trailing whitespace\n",
        "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
        "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
        "        \n",
        "        for w in word_tokenize(sent):\n",
        "            # We are applying some custom filtering here.\n",
        "            # Check if it is not numeric and its length>2 and not in stop words\n",
        "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop_words):  \n",
        "                # Stem and add to filtered list\n",
        "                filtered_sentence.append(snow.stem(w))\n",
        "        final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
        " \n",
        "        final_text_list.append(final_string)\n",
        "    \n",
        "    return final_text_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5reWAJiesX7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "135c0c2a-be01-4519-f944-3bf4ac841bce"
      },
      "source": [
        "print(\"Pre-processing the training text field\")\n",
        "train_df[\"text\"] = process_text(train_df[\"text\"].tolist()) \n",
        "print(\"Pre-processing the test text field\")\n",
        "test_df[\"text\"] = process_text(test_df[\"text\"].tolist())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre-processing the training text field\n",
            "Pre-processing the test text field\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmE1JxrTs9MX",
        "colab_type": "text"
      },
      "source": [
        "We will apply min-max scaling to our rating field so that they will be between 0-1. Note that for scalling the validation and test set we are using the same min and max values computed on the training set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NidJziYLsbme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[\"star_rating\"] = (train_df[\"star_rating\"] - train_df[\"star_rating\"].min())/(train_df[\"star_rating\"].max()-train_df[\"star_rating\"].min())\n",
        "test_df[\"star_rating\"] = (test_df[\"star_rating\"] - test_df[\"star_rating\"].min())/(test_df[\"star_rating\"].max()-test_df[\"star_rating\"].min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HREG4ExFs_yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "# Input: \"text\", \"star_rating\"\n",
        "# Target: \"human_tag\"\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df[[\"text\", \"star_rating\"]],\n",
        "                                                  train_df[\"human_tag\"].tolist(),\n",
        "                                                  test_size=0.10,\n",
        "                                                  shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug-RbgLPtB62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's get our binary vectors for the text field\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        " \n",
        "# Initialize the binary count vectorizer\n",
        "tfidf_vectorizer = CountVectorizer(binary=True,\n",
        "                                   max_features=200    # Limit the vocabulary size\n",
        "                                  )\n",
        "# Fit and transform\n",
        "X_train_text_vectors = tfidf_vectorizer.fit_transform(X_train[\"text\"].tolist())\n",
        "# Only transform\n",
        "X_val_text_vectors = tfidf_vectorizer.transform(X_val[\"text\"].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qcxgcZftFaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9aba1c31-9236-42ed-d850-872d5bf650b7"
      },
      "source": [
        "print(tfidf_vectorizer.vocabulary_)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'say': 151, 'take': 172, 'burnt': 20, 'thing': 175, 'still': 169, 'not': 113, 'smell': 162, 'nice': 112, 'small': 161, 'get': 58, 'realli': 139, 'quick': 135, 'work': 196, 'well': 193, 'bit': 14, 'expect': 46, 'hope': 73, 'could': 31, 'enough': 42, 'notic': 115, 'plastic': 126, 'first': 54, 'start': 166, 'remov': 144, 'put': 133, 'high': 71, 'coupl': 32, 'day': 33, 'better': 12, 'got': 62, 'run': 149, 'without': 195, 'left': 86, 'come': 28, 'back': 9, 'even': 43, 'use': 185, 'worth': 197, 'almost': 2, 'mayb': 102, 'it': 80, 'cheap': 25, 'tri': 182, 'buy': 21, 'someth': 164, 'amazon': 4, 'reason': 140, 'end': 41, 'though': 177, 'bought': 16, 'oil': 116, 'easili': 40, 'return': 146, 'great': 63, 'piec': 124, 'complet': 29, 'turn': 183, 'hour': 75, 'quit': 136, 'place': 125, 'ever': 44, 'sinc': 158, 're': 137, 'like': 90, 'recommend': 142, 'pretti': 127, 'good': 61, 'differ': 36, 'one': 118, 'insid': 78, 'burn': 19, 'also': 3, 'heat': 69, 'leav': 85, 'dri': 38, 'way': 191, 'make': 99, 'top': 181, 'water': 190, 'would': 198, 've': 186, 'stick': 168, 'want': 187, 'size': 159, 'go': 60, 'fit': 55, 'price': 128, 'time': 179, 'last': 84, 'right': 148, 'abl': 0, 'hot': 74, 'tast': 173, 'wash': 188, 'know': 83, 'part': 122, 'two': 184, 'week': 192, 'light': 89, 'stop': 170, 'receiv': 141, 'item': 81, 'issu': 79, 'fire': 53, 'side': 157, 'definit': 34, 'see': 153, 'red': 143, 'love': 97, 'howev': 77, 'lot': 96, 'disappoint': 37, 'anoth': 5, 'old': 117, 'set': 155, 'happen': 67, 'read': 138, 'seem': 154, 'littl': 91, 'clean': 26, 'box': 17, 'never': 110, 'much': 108, 'review': 147, 'anyth': 6, 'hard': 68, 'hand': 65, 'less': 87, 'star': 165, 'handl': 66, 'sever': 156, 'product': 131, 'look': 95, 'cook': 30, 'long': 93, 'problem': 130, 'bottom': 15, 'll': 92, 'need': 109, 'around': 7, 'keep': 82, 'open': 119, 'may': 101, 'thought': 178, 'design': 35, 'order': 120, 'easi': 39, 'hair': 64, 'purchas': 132, 'replac': 145, 'find': 51, 'sure': 171, 'bad': 10, 'far': 49, 'mani': 100, 'made': 98, 'everi': 45, 'month': 107, 'help': 70, 'year': 199, 'went': 194, 'melt': 103, 'probabl': 129, 'second': 152, 'stay': 167, 'feel': 50, 'caus': 24, 'big': 13, 'qualiti': 134, 'perfect': 123, 'came': 22, 'care': 23, 'face': 48, 'brand': 18, 'skin': 160, 'fine': 52, 'said': 150, 'color': 27, 'new': 111, 'longer': 94, 'hold': 72, 'minut': 105, 'found': 57, 'wast': 189, 'noth': 114, 'give': 59, 'money': 106, 'smoke': 163, 'away': 8, 'think': 176, 'let': 88, 'batteri': 11, 'th': 174, 'hous': 76, 'eye': 47, 'actual': 1, 'might': 104, 'took': 180, 'packag': 121, 'food': 56}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRow4xqItLsK",
        "colab_type": "text"
      },
      "source": [
        "#Fitting the KNN classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFySj4J4tI7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4JY5E95tNlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "bedba558-b45c-4d2e-9355-a16c3c434f7a"
      },
      "source": [
        "# Let' merge our features\n",
        "X_train_features = np.column_stack((X_train_text_vectors.toarray(), \n",
        "                                    X_train[\"star_rating\"].values)\n",
        "                                  )\n",
        "# Let' merge our features\n",
        "X_val_features = np.column_stack((X_val_text_vectors.toarray(), \n",
        "                                    X_val[\"star_rating\"].values)\n",
        "                                  )\n",
        " \n",
        "K_values = [3, 5, 10, 20, 30]\n",
        " \n",
        "for K in K_values:\n",
        "    knnClassifier = KNeighborsClassifier(n_neighbors=K)\n",
        "    knnClassifier.fit(X_train_features, y_train)\n",
        "    val_predictions = knnClassifier.predict(X_val_features)\n",
        "    print(\"F1 Score for K:\", K, \"is\", f1_score(y_val, val_predictions))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score for K: 3 is 0.31451612903225806\n",
            "F1 Score for K: 5 is 0.2952076677316294\n",
            "F1 Score for K: 10 is 0.1953562850280224\n",
            "F1 Score for K: 20 is 0.19259259259259257\n",
            "F1 Score for K: 30 is 0.144702842377261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkBF65NtTfJ",
        "colab_type": "text"
      },
      "source": [
        "#Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfPWCr_utSRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here, we will pick the best performing model from above. K=3 yields the best result, we will use it.\n",
        "\n",
        "# Get binary features for the test text field\n",
        "X_test_text_vectors = tfidf_vectorizer.transform(test_df[\"text\"].tolist())\n",
        " \n",
        "# Let's merge the fields of interest\n",
        "X_test_features = np.column_stack((X_test_text_vectors.toarray(), \n",
        "                                  test_df[\"star_rating\"].values)\n",
        "                                  )\n",
        " \n",
        "# Fitting the classifier first\n",
        "knnClassifier = KNeighborsClassifier(n_neighbors=3)\n",
        "knnClassifier.fit(X_train_features, y_train)\n",
        " \n",
        "# Predicting on test features\n",
        "test_predictions = knnClassifier.predict(X_test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQmM1hAgtP8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "f673cc27-cdac-49af-8904-ec32a4833c4c"
      },
      "source": [
        "print(test_df[\"text\"][13])\n",
        "print('______________________________')\n",
        "print(test_df[\"text\"][27])\n",
        "print('______________________________')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inaccur ... put oven set 350f minut still read went increas oven temperatur reach complet burn food bake\n",
            "______________________________\n",
            "volum low not worth buy left long heat start burn speaker touch\n",
            "______________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jluw9R1xtjSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This was predicted as not safe by our model. That's great! It seems to have predicted correctly."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhQn102dtm7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "54696964-64d4-44a4-9140-6715303c4c8c"
      },
      "source": [
        "print(test_df[\"text\"][44])\n",
        "print('______________________________')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "would like say light bright wish would send new ine due half light work n't even longer enough enjoy pleas help send photo like light burn\n",
            "______________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDp1k3yBtpg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#However, it is not perfect yet as the above review was marked incorrectly as not safe."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}