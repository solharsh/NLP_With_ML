{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/thanish/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "import tokenizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanish/Competition/Zindi/Tech4MentalHealth/Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_path' : '../data/train_corrected.csv',\n",
    "          'test_path' : '../data/test_corrected.csv',\n",
    "          'train_batch_size' : 4,\n",
    "          'valid_batch_size' : 8,\n",
    "          'test_batch_size' : 64,\n",
    "          'MAX_LEN' : 196,\n",
    "          'EPOCH' : 3, \n",
    "          'BERT_PATH_desktop': '/home/thanish/bert_base_uncased',\n",
    "          }\n",
    "\n",
    "TOKENIZER = transformers.BertTokenizer(os.path.join(config['BERT_PATH_desktop'], 'vocab.txt'),lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            i feel that it was better i dream happy  Depression\n",
       "1  9JDAGUV3                        why do i get hallucinations       Drugs\n",
       "2  419WR1LQ  i am stressed due to lack of financial support...  Depression\n",
       "3  6UY7DX6Q                              why is life important     Suicide\n",
       "4  FYC0FTFB  how could i be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF = pd.read_csv(config['train_path'])\n",
    "test_DF = pd.read_csv(config['test_path'])\n",
    "\n",
    "train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>BOHSNXCN</td>\n",
       "      <td>what should i do to stop alcoholism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>GVDXRQPY</td>\n",
       "      <td>how to become my oneself again</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>IO4JHIQS</td>\n",
       "      <td>how can someone stop it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1DS3P1XO</td>\n",
       "      <td>i feel unworthy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ORF71PVQ</td>\n",
       "      <td>i feel so discouraged with life</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               text  Alcohol  \\\n",
       "0    SUAVK39Z            i feel that it was better i dream happy        0   \n",
       "1    9JDAGUV3                        why do i get hallucinations        0   \n",
       "2    419WR1LQ  i am stressed due to lack of financial support...        0   \n",
       "3    6UY7DX6Q                              why is life important        0   \n",
       "4    FYC0FTFB  how could i be helped to go through the depres...        0   \n",
       "..        ...                                                ...      ...   \n",
       "611  BOHSNXCN                what should i do to stop alcoholism        1   \n",
       "612  GVDXRQPY                     how to become my oneself again        0   \n",
       "613  IO4JHIQS                            how can someone stop it        1   \n",
       "614  1DS3P1XO                                    i feel unworthy        0   \n",
       "615  ORF71PVQ                    i feel so discouraged with life        0   \n",
       "\n",
       "     Depression  Drugs  Suicide  \n",
       "0             1      0        0  \n",
       "1             0      1        0  \n",
       "2             1      0        0  \n",
       "3             0      0        1  \n",
       "4             1      0        0  \n",
       "..          ...    ...      ...  \n",
       "611           0      0        0  \n",
       "612           0      0        1  \n",
       "613           0      0        0  \n",
       "614           1      0        0  \n",
       "615           1      0        0  \n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the label to OHE\n",
    "train_DF = pd.concat([train_DF[['ID', 'text']], pd.get_dummies(train_DF.label)], axis = 1)\n",
    "train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 6) (124, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "train_local, valid_local = train_test_split(train_DF,\n",
    "                                            test_size = 0.2,\n",
    "                                            random_state = 100)\n",
    "\n",
    "train_local = train_local.reset_index(drop = True)\n",
    "valid_local = valid_local.reset_index(drop = True)\n",
    "\n",
    "print(train_local.shape, valid_local.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class form_input():\n",
    "    \n",
    "    def __init__(self, text_id, text, label, data_type = 'test'):\n",
    "        self.data_type = data_type\n",
    "        self.text_id = text_id\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.max_len = config['MAX_LEN']\n",
    "        self.tokenizer = TOKENIZER\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  TOKENIZER.encode_plus(self.text[item])\n",
    "        \n",
    "        sub_id = self.text_id[item]\n",
    "        ids = inputs['input_ids']\n",
    "        tok_type_id = inputs['token_type_ids']\n",
    "        att_mask = inputs['attention_mask']\n",
    "        pad_len = self.max_len - len(ids)\n",
    "\n",
    "        ids = ids + [0]*pad_len\n",
    "        tok_type_id = tok_type_id + [0]*pad_len\n",
    "        att_mask = att_mask + [0]*pad_len\n",
    "        \n",
    "        if self.data_type != 'test':\n",
    "            label = self.label[item]\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        return {'sub_id': sub_id,\n",
    "                #'Actual_text': self.text[item],\n",
    "                'ids': torch.tensor(ids, dtype = torch.long),\n",
    "                'mask': torch.tensor(att_mask, dtype = torch.long),\n",
    "                'token_type_ids': torch.tensor(tok_type_id, dtype = torch.long),\n",
    "                'targets': torch.tensor(label, dtype = torch.long)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_id': 'BOHSNXCN',\n",
       " 'ids': tensor([  101,  2054,  2323,  1045,  2079,  2000,  2644, 25519,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'targets': tensor([1, 0, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "\n",
    "train_local_data = form_input(train_local.ID, train_local.text, train_local[lab_columns].values, 'train')\n",
    "valid_local_data = form_input(valid_local.ID, valid_local.text, valid_local[lab_columns].values, 'train')\n",
    "train_prod_data = form_input(train_DF.ID, train_DF.text, train_DF[lab_columns].values, 'train')\n",
    "test_prod_data = form_input(test_DF.ID, test_DF.text, None, 'test')\n",
    "\n",
    "train_local_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local_data_loader = DataLoader(train_local_data, \n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(train_local_data),\n",
    "                                     batch_size=config['train_batch_size'])\n",
    "valid_local_data_loader = DataLoader(valid_local_data,\n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(valid_local_data),\n",
    "                                     batch_size=config['valid_batch_size'])\n",
    "\n",
    "train_prod_data_loader = DataLoader(train_prod_data, \n",
    "                                    #shuffle=True,\n",
    "                                    sampler = RandomSampler(train_prod_data),\n",
    "                                    batch_size=config['train_batch_size'])\n",
    "\n",
    "test_prod_data_loader = DataLoader(test_prod_data,\n",
    "                                   #shuffle=False,\n",
    "                                   sampler = SequentialSampler(test_prod_data),\n",
    "                                   batch_size=config['test_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTMultiLabelSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTMultiLabelSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.xlnet = transformers.BertModel.from_pretrained(config['BERT_PATH_Azure'])\n",
    "        self.classifier = torch.nn.Linear(768, self.num_labels)\n",
    "        \n",
    "    def pool_hidden_state(self, last_hidden_state):\n",
    "        \"Pool the hidden output into a single mean vector\"\n",
    "        last_hidden_state = last_hidden_state[0]\n",
    "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "        return mean_last_hidden_state\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids = None, attention_mask = None, labels = None):\n",
    "        # Last layer\n",
    "        last_hidden_state = self.xlnet(input_ids = input_ids, \n",
    "                                       token_type_ids = token_type_ids,\n",
    "                                       attention_mask = attention_mask\n",
    "                                       )\n",
    "        # Pooled the outputs in a mean vector\n",
    "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "        logits = self.classifier(mean_last_hidden_state)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.view(-1, self.num_labels))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count()>1:\n",
    "    print(\"It has {} GPUs\".format(torch.cuda.device_count()))\n",
    "\n",
    "    random.seed(100)\n",
    "    np.random.seed(100)\n",
    "    torch.manual_seed(100)\n",
    "    torch.cuda.manual_seed_all(100)\n",
    "    \n",
    "    model = BERTMultiLabelSequenceClassification(num_labels = len(lab_columns))\n",
    "    \n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "    \n",
    "#loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr = 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    random.seed(100)\n",
    "    np.random.seed(100)\n",
    "    torch.manual_seed(100)\n",
    "    torch.cuda.manual_seed_all(100)\n",
    "    \n",
    "    train_loss  = 0\n",
    "    for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "        ids = dataset['ids'].to(device, dtype = torch.long)\n",
    "        mask = dataset['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = dataset['token_type_ids'].to(device, dtype = torch.long)\n",
    "        target = dataset['targets'].to(device, dtype = torch.float)\n",
    "    \n",
    "        output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "        \n",
    "        step_loss = output[0]\n",
    "         \n",
    "        step_loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += step_loss\n",
    "        \n",
    "    print('Saving the model')\n",
    "    torch.save(model, '../output/best_Bert_base_model.bin')\n",
    "    \n",
    "    print(\"Avg Train loss\" , (train_loss/len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    actual_output = []\n",
    "    predicted_output = []\n",
    "    with torch.no_grad():\n",
    "        for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            ids = dataset['ids'].to(device)\n",
    "            token_type_ids = dataset['token_type_ids'].to(device)\n",
    "            mask = dataset['mask'].to(device)\n",
    "            target = dataset['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "            \n",
    "            step_loss = output[0]\n",
    "            prediction = output[1]\n",
    "            \n",
    "            eval_loss += step_loss\n",
    "            \n",
    "            actual_output.extend(target.detach().cpu().numpy().tolist())\n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        print(\"Avg Eval loss\" , (eval_loss/len(data_loader)))\n",
    "        \n",
    "        return actual_output, predicted_output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:09<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.2913, 0.2686], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n",
      "  0%|          | 0/154 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.1332, 0.0963], device='cuda:0')\n",
      "Epoch 0/3 Logloss: 0.257651980305391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:08<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.0807, 0.0752], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.89it/s]\n",
      "  0%|          | 0/154 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.0460, 0.0434], device='cuda:0')\n",
      "Epoch 1/3 Logloss: 0.10625287875412934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [01:08<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.0405, 0.0363], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.0389, 0.0428], device='cuda:0')\n",
      "Epoch 2/3 Logloss: 0.09431236906487855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Training\n",
    "    train_fn(data_loader = train_prod_data_loader,\n",
    "             model = model,\n",
    "             optimizer = optimizer)\n",
    "    \n",
    "    # Evaluation\n",
    "    actual, predicted = eval_fn(data_loader = valid_local_data_loader,\n",
    "                                model = model)\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    #predicted_prob = np.array(predicted)\n",
    "    predicted_prob = predicted\n",
    "    predicted_class = np.argmax(np.array(predicted), axis = 1)\n",
    "\n",
    "#    acc = accuracy_score(actual, predicted_class)\n",
    "    log_ls = log_loss(actual, torch.tensor(predicted_prob).sigmoid())    \n",
    "    \n",
    "#    print(\"Epoch {}/{} Eval Accuracy: {}, Logloss: {}\".format(epoch, EPOCHS, acc, log_ls))\n",
    "    print(\"Epoch {}/{} Logloss: {}\".format(epoch, EPOCHS, log_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]]),\n",
       " array([0, 1, 3, 0, 0, 2, 1, 1, 1, 3, 2, 1, 0, 1, 1, 1, 3, 1, 3, 1, 1, 0,\n",
       "        2, 1, 3, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1,\n",
       "        3, 1, 0, 3, 2, 2, 1, 3, 0, 1, 0, 0, 0, 0, 3, 1, 1, 1, 1, 2, 3, 1,\n",
       "        1, 1, 2, 1, 1, 1, 0, 1, 1, 3, 1, 1, 0, 3, 0, 1, 1, 2, 1, 1, 3, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 2, 1, 1, 0, 1,\n",
       "        3, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 0, 1]),\n",
       " tensor([[0.9938, 0.0153, 0.0057, 0.0110],\n",
       "         [0.0083, 0.9920, 0.0024, 0.0080],\n",
       "         [0.0057, 0.4298, 0.0024, 0.5962],\n",
       "         [0.9916, 0.0209, 0.0058, 0.0123],\n",
       "         [0.9951, 0.0122, 0.0065, 0.0114],\n",
       "         [0.0173, 0.0232, 0.8931, 0.0037],\n",
       "         [0.0088, 0.9932, 0.0030, 0.0071],\n",
       "         [0.0064, 0.9963, 0.0044, 0.0048],\n",
       "         [0.0105, 0.9945, 0.0045, 0.0044],\n",
       "         [0.0167, 0.0157, 0.0093, 0.9902],\n",
       "         [0.0203, 0.0175, 0.9526, 0.0035],\n",
       "         [0.0059, 0.9966, 0.0047, 0.0045],\n",
       "         [0.9549, 0.0382, 0.0042, 0.0237],\n",
       "         [0.0071, 0.9967, 0.0045, 0.0044],\n",
       "         [0.0062, 0.9894, 0.0026, 0.0120],\n",
       "         [0.0059, 0.9963, 0.0051, 0.0050],\n",
       "         [0.0124, 0.0163, 0.0115, 0.9915],\n",
       "         [0.0056, 0.9951, 0.0033, 0.0065],\n",
       "         [0.0231, 0.0909, 0.0029, 0.8597],\n",
       "         [0.0043, 0.9942, 0.0031, 0.0087],\n",
       "         [0.0069, 0.9952, 0.0036, 0.0059],\n",
       "         [0.9949, 0.0151, 0.0063, 0.0108],\n",
       "         [0.0179, 0.0126, 0.9537, 0.0055],\n",
       "         [0.0063, 0.9956, 0.0041, 0.0046],\n",
       "         [0.0116, 0.0688, 0.0034, 0.9659],\n",
       "         [0.0057, 0.9962, 0.0049, 0.0046],\n",
       "         [0.9948, 0.0138, 0.0064, 0.0106],\n",
       "         [0.9950, 0.0118, 0.0064, 0.0110],\n",
       "         [0.0325, 0.0085, 0.9639, 0.0042],\n",
       "         [0.0070, 0.9958, 0.0044, 0.0053],\n",
       "         [0.0053, 0.9955, 0.0044, 0.0058],\n",
       "         [0.0081, 0.9960, 0.0045, 0.0039],\n",
       "         [0.0068, 0.9934, 0.0030, 0.0074],\n",
       "         [0.0081, 0.9965, 0.0042, 0.0046],\n",
       "         [0.0087, 0.9953, 0.0042, 0.0046],\n",
       "         [0.0103, 0.9957, 0.0046, 0.0048],\n",
       "         [0.0056, 0.9958, 0.0038, 0.0056],\n",
       "         [0.0267, 0.0072, 0.9688, 0.0065],\n",
       "         [0.0060, 0.9964, 0.0046, 0.0044],\n",
       "         [0.0070, 0.9960, 0.0044, 0.0042],\n",
       "         [0.0063, 0.9956, 0.0041, 0.0046],\n",
       "         [0.9947, 0.0141, 0.0054, 0.0148],\n",
       "         [0.0085, 0.9891, 0.0023, 0.0088],\n",
       "         [0.0061, 0.9957, 0.0041, 0.0048],\n",
       "         [0.0244, 0.0151, 0.0097, 0.9903],\n",
       "         [0.0058, 0.9960, 0.0041, 0.0051],\n",
       "         [0.9947, 0.0131, 0.0063, 0.0120],\n",
       "         [0.0145, 0.0204, 0.0094, 0.9902],\n",
       "         [0.0177, 0.0411, 0.5165, 0.0144],\n",
       "         [0.0156, 0.0089, 0.9772, 0.0090],\n",
       "         [0.0099, 0.9958, 0.0045, 0.0045],\n",
       "         [0.0147, 0.0491, 0.0032, 0.9567],\n",
       "         [0.9935, 0.0111, 0.0069, 0.0109],\n",
       "         [0.0073, 0.9962, 0.0043, 0.0040],\n",
       "         [0.9950, 0.0144, 0.0062, 0.0114],\n",
       "         [0.9951, 0.0141, 0.0065, 0.0101],\n",
       "         [0.9878, 0.0111, 0.0080, 0.0152],\n",
       "         [0.9952, 0.0126, 0.0065, 0.0113],\n",
       "         [0.0191, 0.3414, 0.0016, 0.6405],\n",
       "         [0.0070, 0.9960, 0.0040, 0.0043],\n",
       "         [0.0085, 0.9958, 0.0038, 0.0053],\n",
       "         [0.0068, 0.9965, 0.0049, 0.0039],\n",
       "         [0.0093, 0.9961, 0.0039, 0.0043],\n",
       "         [0.0165, 0.0097, 0.9789, 0.0060],\n",
       "         [0.0727, 0.0717, 0.0087, 0.9007],\n",
       "         [0.0063, 0.9946, 0.0037, 0.0053],\n",
       "         [0.0078, 0.9961, 0.0041, 0.0046],\n",
       "         [0.0124, 0.9949, 0.0046, 0.0045],\n",
       "         [0.1790, 0.0031, 0.8268, 0.0027],\n",
       "         [0.0066, 0.9961, 0.0045, 0.0043],\n",
       "         [0.0070, 0.9961, 0.0050, 0.0040],\n",
       "         [0.0119, 0.9917, 0.0028, 0.0070],\n",
       "         [0.9948, 0.0110, 0.0064, 0.0118],\n",
       "         [0.0060, 0.9951, 0.0035, 0.0057],\n",
       "         [0.0066, 0.9952, 0.0042, 0.0052],\n",
       "         [0.0127, 0.0322, 0.0080, 0.9869],\n",
       "         [0.0062, 0.9967, 0.0049, 0.0044],\n",
       "         [0.0090, 0.9952, 0.0041, 0.0053],\n",
       "         [0.9949, 0.0124, 0.0065, 0.0103],\n",
       "         [0.0303, 0.0172, 0.0072, 0.9874],\n",
       "         [0.9951, 0.0131, 0.0065, 0.0116],\n",
       "         [0.0067, 0.9952, 0.0030, 0.0065],\n",
       "         [0.0076, 0.9963, 0.0042, 0.0047],\n",
       "         [0.0272, 0.0328, 0.7928, 0.0019],\n",
       "         [0.0084, 0.9957, 0.0036, 0.0045],\n",
       "         [0.0080, 0.9935, 0.0026, 0.0077],\n",
       "         [0.0099, 0.0226, 0.0140, 0.9915],\n",
       "         [0.0063, 0.9966, 0.0045, 0.0045],\n",
       "         [0.9951, 0.0124, 0.0065, 0.0112],\n",
       "         [0.0067, 0.9963, 0.0045, 0.0046],\n",
       "         [0.0069, 0.9939, 0.0033, 0.0077],\n",
       "         [0.0064, 0.9963, 0.0046, 0.0044],\n",
       "         [0.0070, 0.9963, 0.0044, 0.0043],\n",
       "         [0.0078, 0.9962, 0.0041, 0.0042],\n",
       "         [0.0074, 0.9966, 0.0046, 0.0043],\n",
       "         [0.9943, 0.0175, 0.0054, 0.0117],\n",
       "         [0.0086, 0.9941, 0.0043, 0.0047],\n",
       "         [0.9948, 0.0124, 0.0061, 0.0121],\n",
       "         [0.9949, 0.0140, 0.0063, 0.0107],\n",
       "         [0.9950, 0.0121, 0.0067, 0.0109],\n",
       "         [0.9938, 0.0153, 0.0057, 0.0110],\n",
       "         [0.0061, 0.9963, 0.0040, 0.0049],\n",
       "         [0.9954, 0.0136, 0.0065, 0.0114],\n",
       "         [0.0051, 0.9960, 0.0040, 0.0063],\n",
       "         [0.0100, 0.9958, 0.0035, 0.0042],\n",
       "         [0.0126, 0.0153, 0.9758, 0.0066],\n",
       "         [0.0076, 0.9963, 0.0049, 0.0040],\n",
       "         [0.0094, 0.9948, 0.0046, 0.0048],\n",
       "         [0.9950, 0.0117, 0.0066, 0.0115],\n",
       "         [0.0072, 0.9937, 0.0041, 0.0067],\n",
       "         [0.0087, 0.0205, 0.0120, 0.9900],\n",
       "         [0.9920, 0.0086, 0.0069, 0.0128],\n",
       "         [0.0069, 0.9938, 0.0035, 0.0063],\n",
       "         [0.0106, 0.9925, 0.0028, 0.0054],\n",
       "         [0.0070, 0.9961, 0.0050, 0.0040],\n",
       "         [0.0038, 0.9921, 0.0025, 0.0119],\n",
       "         [0.0128, 0.9938, 0.0046, 0.0045],\n",
       "         [0.9951, 0.0123, 0.0068, 0.0102],\n",
       "         [0.0157, 0.9904, 0.0057, 0.0041],\n",
       "         [0.0070, 0.9958, 0.0036, 0.0047],\n",
       "         [0.0057, 0.9964, 0.0044, 0.0049],\n",
       "         [0.0186, 0.0780, 0.0035, 0.9423],\n",
       "         [0.9924, 0.0125, 0.0072, 0.0103],\n",
       "         [0.0057, 0.9958, 0.0041, 0.0050]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "submission_ID = []\n",
    "with torch.no_grad():\n",
    "    for index, dataset in tqdm(enumerate(test_prod_data_loader), total = len(test_prod_data_loader)):\n",
    "        sub_id = dataset['sub_id']\n",
    "        ids = dataset['ids'].to(device)\n",
    "        token_type_ids = dataset['token_type_ids'].to(device)\n",
    "        mask = dataset['mask'].to(device)\n",
    "\n",
    "        output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask)\n",
    "        \n",
    "        submission_ID.extend(sub_id)\n",
    "        predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())\n",
    "    predicted_output = np.array(predicted_output)\n",
    "            \n",
    "        #predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.840222</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.178331</td>\n",
       "      <td>0.000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.996217</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.004419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.996504</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.004279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0EPULUM5</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GM4C5GD</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.977285</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.009564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Z9A6ACLK</td>\n",
       "      <td>0.919801</td>\n",
       "      <td>0.016678</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.005580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ZDUOIGKN</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.003320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ZHQ60CCH</td>\n",
       "      <td>0.833529</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.001984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>ZVIJMA4O</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.588533</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.378880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ZYIFAY98</td>\n",
       "      <td>0.130406</td>\n",
       "      <td>0.398780</td>\n",
       "      <td>0.217858</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Depression   Alcohol   Suicide     Drugs\n",
       "0    02V56KMO    0.840222  0.017918  0.178331  0.000914\n",
       "1    03BMGTOK    0.996217  0.005663  0.005181  0.004419\n",
       "2    03LZVFM6    0.996504  0.005618  0.004886  0.004279\n",
       "3    0EPULUM5    0.996423  0.005957  0.004646  0.004397\n",
       "4    0GM4C5GD    0.022224  0.977285  0.004340  0.009564\n",
       "..        ...         ...       ...       ...       ...\n",
       "304  Z9A6ACLK    0.919801  0.016678  0.022881  0.005580\n",
       "305  ZDUOIGKN    0.993578  0.011853  0.005127  0.003320\n",
       "306  ZHQ60CCH    0.833529  0.033575  0.066997  0.001984\n",
       "307  ZVIJMA4O    0.003794  0.588533  0.001981  0.378880\n",
       "308  ZYIFAY98    0.130406  0.398780  0.217858  0.001116\n",
       "\n",
       "[309 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.DataFrame(predicted_output)\n",
    "final_output.columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "final_output['ID'] = submission_ID\n",
    "\n",
    "final_output = final_output[['ID', 'Depression', 'Alcohol', 'Suicide', 'Drugs']]\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
