{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bookings_dot_com_sentiment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1W93MPmk24zqobBn6INugHz51zKQ2Gf1q",
      "authorship_tag": "ABX9TyM9XxTXumxlaeYUGRgAVd61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solharsh/NLP_With_ML/blob/master/bookings_dot_com_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojOFFnk6vLgm",
        "colab_type": "text"
      },
      "source": [
        "The data was scraped from Booking.com. All data in the file is publicly available to everyone already. Data is originally owned by Booking.com. \n",
        "\n",
        "# Data Context\n",
        "This dataset contains 515,000 customer reviews and scoring of 1493 luxury hotels across Europe. Meanwhile, the geographical location of hotels are also provided for further analysis.\n",
        "\n",
        "# Data Content\n",
        "The csv file contains 17 fields. The description of each field is as below:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Hotel_Address: Address of hotel.\n",
        "Review_Date: Date when reviewer posted the corresponding review.\n",
        "Average_Score: Average Score of the hotel, calculated based on the latest comment in the last year.\n",
        "Hotel_Name: Name of Hotel\n",
        "Reviewer_Nationality: Nationality of Reviewer\n",
        "Negative_Review: Negative Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Negative'\n",
        "ReviewTotalNegativeWordCounts: Total number of words in the negative review.\n",
        "Positive_Review: Positive Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Positive'\n",
        "ReviewTotalPositiveWordCounts: Total number of words in the positive review.\n",
        "Reviewer_Score: Score the reviewer has given to the hotel, based on his/her experience\n",
        "TotalNumberofReviewsReviewerHasGiven: Number of Reviews the reviewers has given in the past.\n",
        "TotalNumberof_Reviews: Total number of valid reviews the hotel has.\n",
        "Tags: Tags reviewer gave the hotel.\n",
        "dayssincereview: Duration between the review date and scrape date.\n",
        "AdditionalNumberof_Scoring: There are also some guests who just made a scoring on the service rather than a review. This number indicates how many valid scores without review in there.\n",
        "lat: Latitude of the hotel\n",
        "lng: longtitude of the hotel\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWLQK4qfwBpb",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "Sentiment analysis is part of the Natural Language Processing (NLP) techniques that consists in extracting emotions related to some raw texts. This is usually used on social media posts and customer reviews in order to automatically understand if some users are positive or negative and why. The goal of this study is to show how sentiment analysis can be performed using python. \n",
        "\n",
        "We will use here some hotel reviews data. Each observation consists in one customer review for one hotel. Each customer review is composed of a textual feedback of the customer's experience at the hotel and an overall rating. The data can be found here: https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe\n",
        "\n",
        "For each textual review, we want to predict if it corresponds to a good review (the customer is happy) or to a bad one (the customer is not satisfied). The reviews overall ratings can range from 2.5/10 to 10/10. In order to simplify the problem we will split those into two categories:\n",
        "\n",
        "bad reviews have overall ratings < 5\n",
        "good reviews have overall ratings >= 5\n",
        "\n",
        "The challenge here is to be able to predict this information using only the raw textual data from the review. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe40OWmawcPZ",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "We first start by loading the raw data. Each textual reviews is splitted into a positive part and a negative part. We group them together in order to start with only raw text data and no other information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24FP7fhRyMcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0rZJxZi83XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/NLP/2142_3597_bundle_archive.zip\" -d \"/content/drive/My Drive/NLP\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoeJ81P_8RJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = pd.read_csv(\"/content/drive/My Drive/NLP/Hotel_Reviews.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kewcTDU39gOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "a4ed4bb9-29e6-4851-d969-cfbec6ccaa4c"
      },
      "source": [
        "reviews_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hotel_Address</th>\n",
              "      <th>Additional_Number_of_Scoring</th>\n",
              "      <th>Review_Date</th>\n",
              "      <th>Average_Score</th>\n",
              "      <th>Hotel_Name</th>\n",
              "      <th>Reviewer_Nationality</th>\n",
              "      <th>Negative_Review</th>\n",
              "      <th>Review_Total_Negative_Word_Counts</th>\n",
              "      <th>Total_Number_of_Reviews</th>\n",
              "      <th>Positive_Review</th>\n",
              "      <th>Review_Total_Positive_Word_Counts</th>\n",
              "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
              "      <th>Reviewer_Score</th>\n",
              "      <th>Tags</th>\n",
              "      <th>days_since_review</th>\n",
              "      <th>lat</th>\n",
              "      <th>lng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
              "      <td>194</td>\n",
              "      <td>8/3/2017</td>\n",
              "      <td>7.7</td>\n",
              "      <td>Hotel Arena</td>\n",
              "      <td>Russia</td>\n",
              "      <td>I am so angry that i made this post available...</td>\n",
              "      <td>397</td>\n",
              "      <td>1403</td>\n",
              "      <td>Only the park outside of the hotel was beauti...</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
              "      <td>0 days</td>\n",
              "      <td>52.360576</td>\n",
              "      <td>4.915968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
              "      <td>194</td>\n",
              "      <td>8/3/2017</td>\n",
              "      <td>7.7</td>\n",
              "      <td>Hotel Arena</td>\n",
              "      <td>Ireland</td>\n",
              "      <td>No Negative</td>\n",
              "      <td>0</td>\n",
              "      <td>1403</td>\n",
              "      <td>No real complaints the hotel was great great ...</td>\n",
              "      <td>105</td>\n",
              "      <td>7</td>\n",
              "      <td>7.5</td>\n",
              "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
              "      <td>0 days</td>\n",
              "      <td>52.360576</td>\n",
              "      <td>4.915968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
              "      <td>194</td>\n",
              "      <td>7/31/2017</td>\n",
              "      <td>7.7</td>\n",
              "      <td>Hotel Arena</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
              "      <td>42</td>\n",
              "      <td>1403</td>\n",
              "      <td>Location was good and staff were ok It is cut...</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>7.1</td>\n",
              "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
              "      <td>3 days</td>\n",
              "      <td>52.360576</td>\n",
              "      <td>4.915968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
              "      <td>194</td>\n",
              "      <td>7/31/2017</td>\n",
              "      <td>7.7</td>\n",
              "      <td>Hotel Arena</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
              "      <td>210</td>\n",
              "      <td>1403</td>\n",
              "      <td>Great location in nice surroundings the bar a...</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
              "      <td>3 days</td>\n",
              "      <td>52.360576</td>\n",
              "      <td>4.915968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
              "      <td>194</td>\n",
              "      <td>7/24/2017</td>\n",
              "      <td>7.7</td>\n",
              "      <td>Hotel Arena</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>You When I booked with your company on line y...</td>\n",
              "      <td>140</td>\n",
              "      <td>1403</td>\n",
              "      <td>Amazing location and building Romantic setting</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
              "      <td>10 days</td>\n",
              "      <td>52.360576</td>\n",
              "      <td>4.915968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Hotel_Address  ...       lng\n",
              "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...  ...  4.915968\n",
              "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...  ...  4.915968\n",
              "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...  ...  4.915968\n",
              "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...  ...  4.915968\n",
              "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...  ...  4.915968\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg0r-DYyvgpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4d7a48c4-5e90-4ed8-ba86-c61eb7b91a0a"
      },
      "source": [
        "# append the positive and negative text reviews\n",
        "reviews_df[\"review\"] = reviews_df[\"Negative_Review\"] + reviews_df[\"Positive_Review\"]\n",
        "# create the label\n",
        "reviews_df[\"is_bad_review\"] = reviews_df[\"Reviewer_Score\"].apply(lambda x: 1 if x < 5 else 0)\n",
        "# select only relevant columns\n",
        "reviews_df = reviews_df[[\"review\", \"is_bad_review\"]]\n",
        "reviews_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>is_bad_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am so angry that i made this post available...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No Negative No real complaints the hotel was g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You When I booked with your company on line y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  is_bad_review\n",
              "0   I am so angry that i made this post available...              1\n",
              "1  No Negative No real complaints the hotel was g...              0\n",
              "2   Rooms are nice but for elderly a bit difficul...              0\n",
              "3   My room was dirty and I was afraid to walk ba...              1\n",
              "4   You When I booked with your company on line y...              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAYTnq-O9zxs",
        "colab_type": "text"
      },
      "source": [
        "# Clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb9lnp0U9uXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove 'No Negative' or 'No Positive' from text\n",
        "reviews_df[\"review\"] = reviews_df[\"review\"].apply(lambda x: x.replace(\"No Negative\", \"\").replace(\"No Positive\", \"\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbVXWQA297Ur",
        "colab_type": "text"
      },
      "source": [
        "If the user doesn't leave any negative feedback comment, this will appear as \"No Negative\" in our data. This is the same for the positive comments with the default value \"No Positive\". We have to remove those parts from our texts.\n",
        "\n",
        "The next step consists in cleaning the text data with various operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azOOXOP1-BIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "9c45f87b-a16a-4ac9-dd95-a2af482083ee"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  \n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZt8TI4n94NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "03ea1f8f-5cc7-414e-fd57-58dacd52a0ae"
      },
      "source": [
        "%%time\n",
        "\n",
        "# return the wordnet object value corresponding to the POS tag\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)\n",
        "\n",
        "# clean text data\n",
        "reviews_df[\"review_clean\"] = reviews_df[\"review\"].apply(lambda x: clean_text(x))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13min 13s, sys: 19.4 s, total: 13min 33s\n",
            "Wall time: 13min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlKODY2Wd4gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df.to_csv('/content/drive/My Drive/NLP/review_cleaned.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffGQMRjf-Qyq",
        "colab_type": "text"
      },
      "source": [
        "To clean textual data, we call our custom 'clean_text' function that performs several transformations:\n",
        "\n",
        "```\n",
        "lower the text\n",
        "tokenize the text (split the text into words) and remove the punctuation\n",
        "remove useless words that contain numbers\n",
        "remove useless stop words like 'the', 'a' ,'this' etc.\n",
        "Part-Of-Speech (POS) tagging: assign a tag to every word to define if it corresponds to a noun, a verb etc. using the WordNet lexical database\n",
        "lemmatize the text: transform every word into their root form (e.g. rooms -> room, slept -> sleep)\n",
        "```\n",
        "\n",
        "\n",
        "Now that we have cleaned our data, we can do some feature engineering for our modelization part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcEWEKgr-YRB",
        "colab_type": "text"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MuxrqCwBg5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b2b8b8b0-0e2c-431b-cfd0-207ae974c28f"
      },
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwobTuWW9-eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add sentiment anaylsis columns\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "reviews_df[\"sentiments\"] = reviews_df[\"review\"].apply(lambda x: sid.polarity_scores(x))\n",
        "reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMonaDLU-duD",
        "colab_type": "text"
      },
      "source": [
        "We first start by adding sentiment analysis features because we can guess that customers reviews are highly linked to how they felt about their stay at the hotel. We use Vader, which is a part of the NLTK module designed for sentiment analysis. Vader uses a lexicon of words to find which ones are positives or negatives. It also takes into account the context of the sentences to determine the sentiment scores. For each text, Vader returns 4 values:\n",
        "\n",
        "```\n",
        "a neutrality score\n",
        "a positivity score\n",
        "a negativity score\n",
        "an overall score that summarizes the previous scores\n",
        "```\n",
        "\n",
        "\n",
        "We will integrate those 4 values as features in our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9U1vYrJ-a1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add number of characters column\n",
        "reviews_df[\"nb_chars\"] = reviews_df[\"review\"].apply(lambda x: len(x))\n",
        "\n",
        "# add number of words column\n",
        "reviews_df[\"nb_words\"] = reviews_df[\"review\"].apply(lambda x: len(x.split(\" \")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uGLQiir-lXb",
        "colab_type": "text"
      },
      "source": [
        "Next, we add some simple metrics for every text:\n",
        "\n",
        "- number of characters in the text\n",
        "- number of words in the text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvss5L7depxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df.to_csv('/content/drive/My Drive/NLP/review_cleaned.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-EpyqZs-jvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create doc2vec vector columns\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews_df[\"review_clean\"].apply(lambda x: x.split(\" \")))]\n",
        "\n",
        "# train a Doc2Vec model with our text data\n",
        "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
        "\n",
        "# transform each document into a vector data\n",
        "doc2vec_df = reviews_df[\"review_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
        "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
        "reviews_df = pd.concat([reviews_df, doc2vec_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKn2o-cN-q5I",
        "colab_type": "text"
      },
      "source": [
        "The next step consist in extracting vector representations for every review. The module Gensim creates a numerical vector representation of every word in the corpus by using the contexts in which they appear (Word2Vec). This is performed using shallow neural networks. What's interesting is that similar words will have similar representation vectors.\n",
        "\n",
        "Each text can also be transformed into numerical vectors using the word vectors (Doc2Vec). Same texts will also have similar representations and that is why we can use those vectors as training features.\n",
        "\n",
        "We first have to train a Doc2Vec model by feeding in our text data. By applying this model on our reviews, we can get those representation vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCxWJrXy-ppg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add tf-idfs columns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df = 10)\n",
        "tfidf_result = tfidf.fit_transform(reviews_df[\"review_clean\"]).toarray()\n",
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
        "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
        "tfidf_df.index = reviews_df.index\n",
        "reviews_df = pd.concat([reviews_df, tfidf_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbATrGI-vcm",
        "colab_type": "text"
      },
      "source": [
        "Finally we add the TF-IDF (Term Frequency - Inverse Document Frequency) values for every word and every document.\n",
        "\n",
        "But why not simply counting how many times each word appears in every document? The problem with this method is that it doesn't take into account the relative importance of words in the texts. A word that appears in almost every text would not likely bring useful information for analysis. On the contrary, rare words may have a lot more of meanings.\n",
        "\n",
        "The TF-IDF metric solves this problem:\n",
        "\n",
        "- TF computes the classic number of times the word appears in the text\n",
        "- IDF computes the relative importance of this word which depends on how many texts the word can be found\n",
        "We add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7v-Cs9--taU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIg678_S-0PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEuq8DxO-3fo",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxtJ3Ssw-1yQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7b306922-c789-4ff2-d300-e57eb4e7c801"
      },
      "source": [
        "# show is_bad_review distribution\n",
        "reviews_df[\"is_bad_review\"].value_counts(normalize = True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.956798\n",
              "1    0.043202\n",
              "Name: is_bad_review, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctmu8t1Irz24",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is highly imbalanced because less than 5% of our reviews are considered as negative ones. This information will be very useful for the modelling part.\n",
        "\n",
        "Now let's print some wordclouds to have a glimpse at what kind of words apear in our reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB4HAuOw-_RR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wordcloud function\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud(\n",
        "        background_color = 'white',\n",
        "        max_words = 200,\n",
        "        max_font_size = 40, \n",
        "        scale = 3,\n",
        "        random_state = 42\n",
        "    ).generate(str(data))\n",
        "\n",
        "    fig = plt.figure(1, figsize = (20, 20))\n",
        "    plt.axis('off')\n",
        "    if title: \n",
        "        fig.suptitle(title, fontsize = 20)\n",
        "        fig.subplots_adjust(top = 2.3)\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()\n",
        "    \n",
        "# print wordcloud\n",
        "show_wordcloud(reviews_df[\"review\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd_-mv7hr6p9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "fa7056d6-2e6a-4016-9ad7-acfd64f296a7"
      },
      "source": [
        "# highest positive sentiment reviews (with more than 5 words)\n",
        "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"pos\", ascending = False)[[\"review\", \"pos\"]].head(10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5dd3a76913d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# highest positive sentiment reviews (with more than 5 words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreviews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreviews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nb_words\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4927\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1708\u001b[0m             raise ValueError(\n\u001b[1;32m   1709\u001b[0m                 (\n\u001b[0;32m-> 1710\u001b[0;31m                     \u001b[0;34mf\"The {label_axis_name} label '{key}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m                     \u001b[0;34mf\"is not unique.{multi_message}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: The column label 'pos' is not unique."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBRpuzUt_BB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "f7eae137-ae46-4c89-b37d-30856a503848"
      },
      "source": [
        "reviews_df.profile_report()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6c503748cc78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'profile_report'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0fuZZCF_EFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}